{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13.14 Tweet Sentiment Analysis \n",
    "* Political researchers might use during elections to understand how people feel about specific politicians and issues, and **how they're likely to vote**\n",
    "* Companies might use to see what people are saying about their products and competitors’ products\n",
    "* Script `sentimentlistener.py` checks sentiment on a specified topic for a specified number of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run sentimentlistener.py football 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Class `SentimentListener`: Imports \n",
    "* Import the keys.py file and the libraries used throughout the script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "```python\n",
    "# sentimentlisener.py\n",
    "\"\"\"Script that searches for tweets that match a search string\n",
    "and tallies the number of positive, neutral and negative tweets.\"\"\"\n",
    "import keys\n",
    "import preprocessor as p \n",
    "import sys\n",
    "from textblob import TextBlob\n",
    "import tweepy\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class `SentimentListener`: `__init__` Method\n",
    "* Receives:\n",
    "    * `bearer_token` for authentication\n",
    "    * `sentiment_dict` dictionary in which we’ll keep track of the tweet sentiments\n",
    "    * `topic` we’re searching for so we can ensure that it appears in the tweet text  \n",
    "    * `limit` of tweets to process (not including the ones we eliminate)\n",
    "* Each of these is stored in the current `SentimentListener` object (`self`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class SentimentListener(tweepy.StreamingClient):\n",
    "    \"\"\"Handles incoming Tweet stream.\"\"\"\n",
    "\n",
    "    def __init__(self, bearer_token, sentiment_dict, topic, limit=10):\n",
    "        \"\"\"Configure the SentimentListener.\"\"\"\n",
    "        self.sentiment_dict = sentiment_dict\n",
    "        self.tweet_count = 0\n",
    "        self.topic = topic\n",
    "        self.TWEET_LIMIT = limit\n",
    "\n",
    "        # set tweet-preprocessor to remove URLs/reserved words\n",
    "        p.set_options(p.OPT.URL, p.OPT.RESERVED) \n",
    "        super().__init__(bearer_token, wait_on_rate_limit=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method `on_response `\n",
    "* If the tweet is not a retweet (line 28):\n",
    "    * Line 29 gets and cleans the tweet’s text \n",
    "    * Lines 32–33 skip the tweet if it does not contain `topic` in the tweet text\n",
    "    * Lines 36–45 use a `TextBlob` to check the tweet’s sentiment and update the `sentiment_dict` accordingly\n",
    "    * Line 48 gets the sender’s `username` from `response.includes['users']` — we’ll use an expansion to include this user object \n",
    "    * Line 49 prints the tweet text preceded by `+` for positive sentiment, a space for neutral sentiment or `-` for negative sentiment\n",
    "    * Line 51 increments the `tweet_count`, and lines 54–55 check whether the app should disconnect from the tweet stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def on_response(self, response):\n",
    "        \"\"\"Called when Twitter pushes a new tweet to you.\"\"\"\n",
    "\n",
    "        # if the tweet is not a retweet\n",
    "        if not response.data.text.startswith('RT'):\n",
    "            text = p.clean(response.data.text) # clean the tweet\n",
    "\n",
    "            # ignore tweet if the topic is not in the tweet text\n",
    "            if self.topic.lower() not in text.lower():\n",
    "                return\n",
    "\n",
    "            # update self.sentiment_dict with the polarity\n",
    "            blob = TextBlob(text)\n",
    "            if blob.sentiment.polarity > 0:\n",
    "                sentiment = '+'\n",
    "                self.sentiment_dict['positive'] += 1 \n",
    "            elif blob.sentiment.polarity == 0:\n",
    "                sentiment = ' '\n",
    "                self.sentiment_dict['neutral'] += 1 \n",
    "            else:\n",
    "                sentiment = '-'\n",
    "                self.sentiment_dict['negative'] += 1 \n",
    "\n",
    "            # display the tweet\n",
    "            username = response.includes['users'][0].username\n",
    "            print(f'{sentiment} {username}: {text}\\n')\n",
    "\n",
    "            self.tweet_count += 1 # track number of tweets processed\n",
    "\n",
    "            # if TWEET_LIMIT is reached, terminate streaming\n",
    "            if self.tweet_count == self.TWEET_LIMIT:\n",
    "                self.disconnect()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Application\n",
    "* The main application is defined in the function `main` (lines 57–87; discussed after the code), which is called by lines 90–91 when you execute the file as a script\n",
    "* `sentimentlistener.py` also can be imported into IPython or other modules to use class `SentimentListener` as we did with `TweetListener`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def main():\n",
    "    # get search term and number of tweets\n",
    "    search_key = sys.argv[1]\n",
    "    limit = int(sys.argv[2]) # number of tweets to tally\n",
    "\n",
    "    # set up the sentiment dictionary\n",
    "    sentiment_dict = {'positive': 0, 'neutral': 0, 'negative': 0}\n",
    "\n",
    "    # create the StreamingClient subclass object\n",
    "    sentiment_listener = SentimentListener(keys.bearer_token, \n",
    "        sentiment_dict, search_key, limit)\n",
    "\n",
    "    # redirect sys.stderr to sys.stdout\n",
    "    sys.stderr = sys.stdout\n",
    "\n",
    "    # delete existing stream rules\n",
    "    rules = sentiment_listener.get_rules().data\n",
    "    rule_ids = [rule.id for rule in rules]\n",
    "    sentiment_listener.delete_rules(rule_ids)    \n",
    "\n",
    "    # create stream rule\n",
    "    sentiment_listener.add_rules(\n",
    "        tweepy.StreamRule(f'{search_key} lang:en'))\n",
    "\n",
    "    # start filtering English tweets containing search_key\n",
    "    sentiment_listener.filter(expansions=['author_id'])\n",
    "\n",
    "    print(f'Tweet sentiment for \"{search_key}\"')\n",
    "    print('Positive:', sentiment_dict['positive'])\n",
    "    print(' Neutral:', sentiment_dict['neutral'])\n",
    "    print('Negative:', sentiment_dict['negative'])\n",
    "\n",
    "# call main if this file is executed as a script\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In `main`:\n",
    "    * Lines 59–60 get the command-line arguments\n",
    "    * Line 63 creates the `sentiment_dict` dictionary that keeps track of the tweet sentiments\n",
    "    * Lines 66–67 create the `SentimentListener` \n",
    "    * Line 70 redirects the standard error stream to the standard output stream\n",
    "    * Lines 73–75 delete any existing `StreamRule`s\n",
    "    * Lines 78–79 create a new `StreamRule` that searches for English (`lang:en`) tweets that match the `search_key`\n",
    "    * Line 82 starts the stream — `expansions` indicates that we’d like Twitter to include the tweet sender’s user object in the response\n",
    "    * Lines 84–87 display the sentiment report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "&copy;1992&ndash;2020 by Pearson Education, Inc. All Rights Reserved. This content is based on Chapter 5 of the book [**Intro to Python for Computer Science and Data Science: Learning to Program with AI, Big Data and the Cloud**](https://amzn.to/2VvdnxE).\n",
    "\n",
    "DISCLAIMER: The authors and publisher of this book have used their \n",
    "best efforts in preparing the book. These efforts include the \n",
    "development, research, and testing of the theories and programs \n",
    "to determine their effectiveness. The authors and publisher make \n",
    "no warranty of any kind, expressed or implied, with regard to these \n",
    "programs or to the documentation contained in these books. The authors \n",
    "and publisher shall not be liable in any event for incidental or \n",
    "consequential damages in connection with, or arising out of, the \n",
    "furnishing, performance, or use of these programs.                  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
