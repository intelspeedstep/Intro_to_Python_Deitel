{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Data Mining Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "* Understand Twitter’s impact on businesses, brands, reputation, sentiment analysis, predictions and more.\n",
    "* Use Tweepy, one of the most popular Python Twitter API clients for data mining Twitter.\n",
    "* Use various Twitter v2 API methods.\n",
    "* Get information about a specific Twitter account.\n",
    "* Search for past tweets that meet your criteria.\n",
    "* Sample the stream of live tweets as they’re happening.\n",
    "* Request additional metadata in Twitter responses via the Twitter v2 API’s expansions and fields. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives (cont.)\n",
    "* Clean and preprocess tweets to prepare them for analysis.\n",
    "* Use NLP techniques you learned in the preceding chapter to translate foreign language tweets into English and to perform sentiment analysis on tweets.\n",
    "* Spot trends with the Twitter v1.1 Trends API.\n",
    "* Map tweets using the folium library and OpenStreetMap map tiles. \n",
    "* Understand various ways to store tweets using techniques discussed throughout this book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Outline\n",
    "* [12.1 Introduction](./12_01.ipynb)\n",
    "* [12.2 Overview of the Twitter APIs](./12_02.ipynb)\n",
    "* [12.3 Creating a Twitter Developer Account](./12_03.ipynb)\n",
    "* [12.4 Getting Twitter Credentials—Creating an App](./12_04.ipynb)\n",
    "* [12.5 What’s in a Twitter API Response?](./12_05.ipynb)\n",
    "* [12.6 Installing `tweepy`, `geopy`, `folium` and `deep-translator`](./12_06.ipynb)\n",
    "* [12.7 Authenticating with Twitter Via Tweepy to Access Twitter v2 APIs](./12_07-11.ipynb) &mdash; Contains sections 12.7-11\n",
    "* 12.8 Getting Information About a Twitter Account\n",
    "* 12.9 Intro to Tweepy `Paginator`s: Getting More Than One Page of Results\n",
    "    * 12.9.1 Determining an Account’s Followers\n",
    "    * 12.9.2 Determining Whom an Account Follows\n",
    "    * 12.9.3 Getting a User’s Recent Tweets\n",
    "* 12.10 Searching Recent Tweets; Intro to Twitter v2 API Search Operators \n",
    "* 12.11 Spotting Trending Topics\n",
    "    * 12.11.1 Places with Trending Topics\n",
    "    * 12.11.2 Getting a List of Trending Topics\n",
    "    * 12.11.3 Create a Word Cloud from Trending Topics\n",
    "* [12.12 Cleaning/Preprocessing Tweets for Analysis](./12_012.ipynb)\n",
    "* [12.13 Twitter Streaming API](./12_13.ipynb)\n",
    "    * 12.13.1 Creating a Subclass of `StreamingClient`\n",
    "    * 12.13.2 Initiating Stream Processing\n",
    "* [12.14 Tweet Sentiment Analysis](./12_14.ipynb)\n",
    "* [12.15 Geocoding and Mapping](./12_15.ipynb)\n",
    "    * 12.15.1 Getting and Mapping the Tweets\n",
    "    * 12.15.2 Utility Functions in `tweetutilities.py`\n",
    "    * 12.15.3 Class `LocationListener`\n",
    "* [12.16 Storing Tweets](./12_16.ipynb)\n",
    "* [12.17 Twitter and Time Series](./12_17.ipynb)\n",
    "* 12.18 Wrap-Up\n",
    "* Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "&copy;1992&ndash;2020 by Pearson Education, Inc. All Rights Reserved. This content is based on Chapter 5 of the book [**Intro to Python for Computer Science and Data Science: Learning to Program with AI, Big Data and the Cloud**](https://amzn.to/2VvdnxE).\n",
    "\n",
    "DISCLAIMER: The authors and publisher of this book have used their \n",
    "best efforts in preparing the book. These efforts include the \n",
    "development, research, and testing of the theories and programs \n",
    "to determine their effectiveness. The authors and publisher make \n",
    "no warranty of any kind, expressed or implied, with regard to these \n",
    "programs or to the documentation contained in these books. The authors \n",
    "and publisher shall not be liable in any event for incidental or \n",
    "consequential damages in connection with, or arising out of, the \n",
    "furnishing, performance, or use of these programs.                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.1 Introduction\n",
    "* We’re always trying to predict the future\n",
    "\t* Will the stock market or individual securities go up or down, and when and by how much? \n",
    "\t* How will people vote in the next election? \n",
    "* Twitter is a popular big-data source for making predictions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.1 Introduction (cont.)\n",
    "* **Data mining** &mdash; searching large collections of data for insights\n",
    "* **Sentiment** in tweets can help make predictions \n",
    "    * Election results\n",
    "    * Likely revenues for a new movie \n",
    "    * Success of a company’s marketing campaign\n",
    "* Could help companies spot faults in competitors’ product offerings\n",
    "* Spot trending topics\n",
    "* Web services connect you to Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter v2 (version 2) Web Service APIs\n",
    "* You’ll \n",
    "    * interact with the Twitter v2 (version 2) web service APIs\n",
    "    * use search criteria to locate tweets\n",
    "    * tap into Twitter’s live tweet stream \n",
    "    * locate worldwide and specific locations’ trending topics\n",
    "    * use powerful libraries to perform significant tasks with just a few lines of code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Is Twitter?\n",
    "* Tweets\n",
    "    * Short messages\n",
    "    * Initially limited to **140 characters**\n",
    "    * Now limited to **280 characters**\n",
    "* Anyone can generally choose to follow anyone else"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter Statistics\n",
    "* [Hundreds of millions of tweets are sent every day with many thousands sent per second](http://www.internetlivestats.com/twitter-statistics/)\n",
    "* Can tap into the live stream of tweets\n",
    "    * Like “drinking from a fire hose,” because the tweets come at you so quickly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter and Big Data \n",
    "* A **favorite big data source** for researchers and business people worldwide\n",
    "* **Free** access to a small portion of recent tweets\n",
    "* Third-parties (and Twitter itself) offer paid access to much larger portions the all-time tweets database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "&copy;1992&ndash;2020 by Pearson Education, Inc. All Rights Reserved. This content is based on Chapter 5 of the book [**Intro to Python for Computer Science and Data Science: Learning to Program with AI, Big Data and the Cloud**](https://amzn.to/2VvdnxE).\n",
    "\n",
    "DISCLAIMER: The authors and publisher of this book have used their \n",
    "best efforts in preparing the book. These efforts include the \n",
    "development, research, and testing of the theories and programs \n",
    "to determine their effectiveness. The authors and publisher make \n",
    "no warranty of any kind, expressed or implied, with regard to these \n",
    "programs or to the documentation contained in these books. The authors \n",
    "and publisher shall not be liable in any event for incidental or \n",
    "consequential damages in connection with, or arising out of, the \n",
    "furnishing, performance, or use of these programs.                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.2 Overview of the Twitter APIs \n",
    "* **Web services** are methods that you call in the **cloud**\n",
    "* Each method has a **web service endpoint**\n",
    "* Represented by a **URL** that’s used to invoke that method over the Internet\n",
    "* **Caution**: Internet connections can be lost, services can change and some services are not available in all countries, so apps can be brittle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.2 Overview of the Twitter APIs (cont.)\n",
    "* Twitter API categories: \n",
    "    * **Users API** — Access information about Twitter user accounts.\n",
    "    * **Tweets API** — Search through past tweets, access tweet streams to tap into tweets happening now and more. \n",
    "    * **Trends API** (from the Twitter v1.1 APIs) — Find locations of trending topics and get lists of trending topics by location. \n",
    "* Additional Twitter API categories and extensive list of subcategories: \n",
    ">https://developer.twitter.com/en/docs/api-reference-index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rate Limits: A Word of Caution \n",
    "* Twitter expects developers to use its services responsibly\n",
    "* **Understand rate limits** before using any method\n",
    "* Twitter may **block you** if you call a given API method after that method’s **rate limit** has been reached\n",
    "* Tweepy can be configured to **wait when it encounters rate limits**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rate Limits: A Word of Caution (cont.)\n",
    "* Some methods list both **user rate limits** and **app rate limits**\n",
    "* We use **app rate limits** in the demos\n",
    "* **User rate limits** are for apps that enable individuals to log into their Twitter accounts\n",
    "* [Details on rate limiting](https://developer.twitter.com/en/docs/basics/rate-limiting)\n",
    "* [Specific rate limits on individual API methods](https://developer.twitter.com/en/docs/basics/rate-limits) — also see each API method’s documentation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Restrictions\n",
    "* **Follow Twitter’s rules/regulations or your developer account could be terminated.** \n",
    "\t* Terms of service — https://twitter.com/tos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "&copy;1992&ndash;2020 by Pearson Education, Inc. All Rights Reserved. This content is based on Chapter 5 of the book [**Intro to Python for Computer Science and Data Science: Learning to Program with AI, Big Data and the Cloud**](https://amzn.to/2VvdnxE).\n",
    "\n",
    "DISCLAIMER: The authors and publisher of this book have used their \n",
    "best efforts in preparing the book. These efforts include the \n",
    "development, research, and testing of the theories and programs \n",
    "to determine their effectiveness. The authors and publisher make \n",
    "no warranty of any kind, expressed or implied, with regard to these \n",
    "programs or to the documentation contained in these books. The authors \n",
    "and publisher shall not be liable in any event for incidental or \n",
    "consequential damages in connection with, or arising out of, the \n",
    "furnishing, performance, or use of these programs.                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.3 Creating a Twitter Account\n",
    "* [Apply for a developer account](https://developer.twitter.com/) to use the APIs\n",
    "* Every application is subject to approval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter Developer Account Levels\n",
    "https://developer.twitter.com/en/products/twitter-api\n",
    "* **Essentials** — “The best way to get started quickly, test, and build across all endpoints.”\n",
    "* **Elevated** — “More access for solutions that are beginning to experience growth or who prefer to work with multiple App environments.”\n",
    "* **Academic Research** — “Access to public data on nearly any topic to advance research objectives of Master’s students, doctoral candidates, post-docs, and faculty at an academic institution or university.”\n",
    "\n",
    "Some Twitter v2 APIs are accessible only to Elevated-level and higher accounts. \n",
    "\n",
    "Twitter documentation specifies the minimum account level and the rate-limit differences between levels, if any."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing a Developer Account Application Type\n",
    "* Professional, Hobbyist, and Academic Research use\n",
    "* choose the type most appropriate for your use case\n",
    "* For this chapter’s examples, you can choose Hobbyist then Exploring the API\n",
    "* If asked to apply for an Elevated application, click **Get started**, then:\n",
    "    1. On the **Basic info** tab, fill in the form with your information and click **Next**.\n",
    "    2. On the **Intended use** tab, describe how you intend to use the APIs. \n",
    "    3. Answer the other questions provided. For this chapter’s examples, you will not use the tweet, retweet, like, follow or direct message functionality; will not display tweets or aggregate data about Twitter content outside of Twitter; and will not make Twitter content available to a government entity.\n",
    "    4. Click **Next** to review your answers, then click **Next** again. \n",
    "    5. Carefully read and agree to Twitter’s **Developer agreement & policy**, then click **Submit** to complete the application. You will be asked to confirm your email address."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Essentials Level Accounts and the Twitter v1.1 APIs\n",
    "* As of mid-2022, Twitter requires new developer accounts to use the Twitter v2 APIs\\\n",
    "* Twitter has not yet migrated some v1.1 APIs to v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "&copy;1992&ndash;2020 by Pearson Education, Inc. All Rights Reserved. This content is based on Chapter 5 of the book [**Intro to Python for Computer Science and Data Science: Learning to Program with AI, Big Data and the Cloud**](https://amzn.to/2VvdnxE).\n",
    "\n",
    "DISCLAIMER: The authors and publisher of this book have used their \n",
    "best efforts in preparing the book. These efforts include the \n",
    "development, research, and testing of the theories and programs \n",
    "to determine their effectiveness. The authors and publisher make \n",
    "no warranty of any kind, expressed or implied, with regard to these \n",
    "programs or to the documentation contained in these books. The authors \n",
    "and publisher shall not be liable in any event for incidental or \n",
    "consequential damages in connection with, or arising out of, the \n",
    "furnishing, performance, or use of these programs.                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.5 What’s in a Twitter API Response?\n",
    "* Twitter API methods return **JSON (JavaScript Object Notation)** objects\n",
    "* Text-based **data-interchange format** \n",
    "* Represents objects as **collections of name–value pairs** (like dictionaries)\n",
    "* Commonly used in web services\n",
    "* Human and computer readable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.5 What’s in a Tweet? (cont.)\n",
    "* **JSON object format**:\n",
    "> ```\n",
    "> {propertyName1: value1, propertyName2: value2}\n",
    "> ```\n",
    "* **JSON array format (like Python list)**:\n",
    "> ```\n",
    "> [value1, value2, value3]\n",
    "> ```\n",
    "* **Tweepy handles the JSON for you** behind the scenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Properties of a Tweet Object\n",
    "Twitter returns a JSON object that, by default, contains \n",
    "* the tweet’s unique ID number \n",
    "* its text (up to a maximum of 280 characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter Metadata and the Twitter v1.1 APIs \n",
    "In Twitter v1.1 APIs, a tweet’s JSON object automatically included many additional metadata attributes that described aspects of the tweet, such as:\n",
    "* when it was created, \n",
    "* who created it, \n",
    "* lists of the hashtags, URLs, @-mentions and media (such as images and videos) included in the tweet,\n",
    "* and more. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter v2 API Expansions and Fields\n",
    "In Twitter v2 API method, you use **fields** and **expansions** to request the precise metadata your app requires\n",
    "* Fields are additional metadata attributes you’d like Twitter to return to your app. For example, when you get a tweet, you might need \n",
    "    * the unique `author_id` attribute, indicating a tweet’s sender, or\n",
    "    * the tweet’s `created_at` attribute, indicating when the user sent the tweet was sent.\n",
    "    * Complete list of tweet fields, visit\n",
    "    https://developer.twitter.com/en/docs/twitter-api/data-dictionary/object-model/tweet\n",
    "* Some fields are associated with other Twitter metadata objects that, in turn, have their own fields\n",
    "* For example, associated with a tweet’s unique `author_id` attribute is a **user JSON object** \n",
    "* You use an **Expansion** to request that Twitter include associated metadata objects\n",
    "* Each associated object will contain its default attributes\n",
    "    * For a user object, these would be the user’s unique id number, name and username, but you can request more\n",
    "    * The complete list of user fields can be viewed at\n",
    "    > https://developer.twitter.com/en/docs/twitter-api/data-dictionary/object-model/user\n",
    "* General overview of all the JSON objects that Twitter APIs return, and links to the specific object details, see\n",
    "> https://developer.twitter.com/en/docs/twitter-api/data-dictionary/introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample JSON for the NASA Account’s 10 Most Recent Tweets\n",
    "* Sample JSON from a Twitter API response to a request that asked for recent tweets from the `@NASA` Twitter account\n",
    "* We added line numbers, reformatted the JSON for readability \n",
    "\n",
    "```\n",
    "{\n",
    "  \"data\": [\n",
    "    {\n",
    "      \"id\": \"1562156100136292352\",\n",
    "      \"text\": \"RT @NASAInSight: Thanks again for all the kind thoughts \n",
    "                   you’ve been sending. There’s still time to write me a note \n",
    "                   for the mission team to…\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"1561886047331487744\",\n",
    "      \"text\": \"We see Martian dust devils (whirlwinds) from the ground, as \n",
    "              in this shot from the Opportunity rover in 2016, left. From \n",
    "                   space, we can see the tracks they leave behind, as in this\n",
    "                   view of dunes from Mars Reconnaissance Orbiter in 2009,\n",
    "                   right. More: https://t.co/kd1BNEDBUD https://t.co/\n",
    "                   RxeKTI5Fv5\"\n",
    "    },\n",
    "    ...\n",
    "  ],\n",
    "  \"meta\": {\n",
    "    \"result_count\": 10,\n",
    "    \"newest_id\": \"1562156100136292352\",\n",
    "    \"oldest_id\": \"1555635141728382976\",\n",
    "    \"next_token\": \"7140dibdnow9c7btw422nm76p6owdso7rqahg96mulyd2\"\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "&copy;1992&ndash;2020 by Pearson Education, Inc. All Rights Reserved. This content is based on Chapter 5 of the book [**Intro to Python for Computer Science and Data Science: Learning to Program with AI, Big Data and the Cloud**](https://amzn.to/2VvdnxE).\n",
    "\n",
    "DISCLAIMER: The authors and publisher of this book have used their \n",
    "best efforts in preparing the book. These efforts include the \n",
    "development, research, and testing of the theories and programs \n",
    "to determine their effectiveness. The authors and publisher make \n",
    "no warranty of any kind, expressed or implied, with regard to these \n",
    "programs or to the documentation contained in these books. The authors \n",
    "and publisher shall not be liable in any event for incidental or \n",
    "consequential damages in connection with, or arising out of, the \n",
    "furnishing, performance, or use of these programs.                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.6 Installing `tweepy`, `geopy`, `folium` and `deep-translator`\n",
    "* [**Tweepy library**](http://www.tweepy.org/)—**one of the most popular Python Twitter clients**\n",
    "* Easy access to Twitter’s capabilities\n",
    "* [Tweepy’s documentation](https://docs.tweepy.org/en/stable/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Tweepy \n",
    "> `pip install tweepy`\n",
    "* Windows users **should run the Anaconda Prompt as an Administrator**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing geopy \n",
    ">`conda install -c conda-forge geopy`\n",
    "* Windows users **should run the Anaconda Prompt as an Administrator**\n",
    "\n",
    "* One function from our `tweetutilities.py` file (in the ch13 folder) depends on [**geopy**](https://github.com/geopy/geopy) (a geocoding library we'll use later to plot tweet locations on a map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### OpenMapQuest Geocoding API\n",
    "* Section 12.15 uses the **OpenMapQuest Geocoding API** to convert locations, such as **Boston, MA**, into their latitudes and longitudes, such as **42.3602534** and **-71.0582912**, for plotting on maps\n",
    "* Currently allows **15,000 transactions per month** on their free tier\n",
    "* Sign up at \n",
    "> https://developer.mapquest.com/\n",
    "* Go to https://developer.mapquest.com/user/me/apps \n",
    "    * Click **Create a New Key**, fill in the **App Name** field with a name of your choosing, leave the **Callback URL** empty and click **Create App** to create an API key\n",
    "    * Click your app’s name to see your consumer key\n",
    "    * In the `keys.py` file, store the consumer key by replacing `YourKeyHere` in the line\n",
    "    > `mapquest_key = 'YourKeyHere'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folium Library and Leaflet.js JavaScript Mapping Library\n",
    "https://github.com/python-visualization/folium\n",
    "> `pip install folium`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maps from OpenStreetMap.org\n",
    "* Leaflet.js uses open-source maps from `OpenStreetMap.org`. \n",
    "* Copyrighted by the OpenStreetMap.org contributors\n",
    "* www.openstreetmap.org/copyright \n",
    "* www.opendatacommons.org/licenses/odbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deep-translator Library\n",
    "Supports several translation services\n",
    "> `pip install -U deep_translator`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "&copy;1992&ndash;2020 by Pearson Education, Inc. All Rights Reserved. This content is based on Chapter 5 of the book [**Intro to Python for Computer Science and Data Science: Learning to Program with AI, Big Data and the Cloud**](https://amzn.to/2VvdnxE).\n",
    "\n",
    "DISCLAIMER: The authors and publisher of this book have used their \n",
    "best efforts in preparing the book. These efforts include the \n",
    "development, research, and testing of the theories and programs \n",
    "to determine their effectiveness. The authors and publisher make \n",
    "no warranty of any kind, expressed or implied, with regard to these \n",
    "programs or to the documentation contained in these books. The authors \n",
    "and publisher shall not be liable in any event for incidental or \n",
    "consequential damages in connection with, or arising out of, the \n",
    "furnishing, performance, or use of these programs.                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.7 Authenticating with Twitter Via Tweepy to Access Twitter v2 APIs\n",
    "* A **Tweepy `Client` object** is your gateway to using the Twitter v2 APIs\n",
    "* Must first **authenticate with Twitter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before executing this cell, ensure that your copy of keys.py \n",
    "# contains your Twitter credentials as described earlier\n",
    "import keys  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a `Client` Object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the Twitter v2 APIs, you must first create a `Client` object, initializing it with your bearer token: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = tweepy.Client(bearer_token=keys.bearer_token,\n",
    "                       wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two arguments:\n",
    "* `bearer_token` is your bearer token \n",
    "* `wait_on_rate_limit=True` tells Tweepy that each time it reaches a given API method’s rate limit it should wait for the rate-limit interval to expire\n",
    "    * This ensures that you do not violate Twitter’s rate-limit restrictions\n",
    "    * For most Twitter APIs, the rate-limit interval is 15 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.8 Getting Information About a Twitter Account\n",
    "Use the Tweepy `Client` object’s `get_user` method to get a `tweepy.Response` object containing information about a @NASA’s Twitter account:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasa = client.get_user(username='NASA',\n",
    "    user_fields=['description', 'public_metrics'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `get_user` with the `username` keyword argument calls the Twitter API method \n",
    "> `/2/users/by/username/:username`\n",
    "* Returns JSON data that Tweepy converts into a `tweepy.Response` \n",
    "* Twitter returns the account’s ID number, name and user name by default\n",
    "* Can request additional user account fields via the `user_fields` keyword argument\n",
    "    * We requested the account’s `description` and `public_metrics`\n",
    "* Complete list of user fields can be viewed at:\n",
    "> https://developer.twitter.com/en/docs/twitter-api/data-dictionary/object-model/user\n",
    "* Each Twitter method has a rate limit\n",
    "    * `/2/users/by/username/:username`\n",
    "    * Can call this method up to 900 times every 15 minutes \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### `tweepy.Response` Object\n",
    "* Contains four fields:\n",
    "    * `data` — contains the data returned by Twitter\n",
    "    * `includes` — additional data specified via the method’s `expansions` parameter \n",
    "    * `errors` — information about any errors that occurred\n",
    "    * `meta` — method-specific information that can be useful in processing the response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a User’s Basic Account Information\n",
    "* When a Twitter method returns a **user JSON object**, `Response`’s `data` attribute is a named tuple containing the default fields:\n",
    "    * `id` is the account’s unique ID number.\n",
    "    * `name` is the name associated with the user’s account.\n",
    "    * `username` is the user’s Twitter handle (`@NASA`) \n",
    "* Additional `user_fields` `description` and `public_metrics` (discussed momentarily) also are in the `Response` object’s `data` attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11348282"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nasa.data.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NASA'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nasa.data.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NASA'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nasa.data.username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"There's space for everybody. ✨\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nasa.data.description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the Number of Accounts That Follow This Account and the Number of Accounts This Account Follows\n",
    "* User account’s `public_metrics` are returned as a dictionary with keys:\n",
    "    * `'followers_count'` — number of users who follow this account, \n",
    "    * `'following_count'` — e number of users that this account follows, \n",
    "    * `'tweet_count'` — total number of tweets (and retweets) sent by this user, and \n",
    "    * `'listed_count'` — total number of Twitter lists that include this user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62900622"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nasa.data.public_metrics['followers_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nasa.data.public_metrics['following_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Your Own Account’s Information\n",
    "* Get via `Client` object’s `get_me` method\n",
    "> me = client.get_me()\n",
    "* Returns a User object for the account you used to authenticate with Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.9 Intro to Tweepy `Paginator`s: Getting More than One Page of Results \n",
    "* Twitter API methods often return collections of objects, such as\n",
    "    * tweets sent by a particular user, \n",
    "    * tweets matching specified search criteria or \n",
    "    * tweets in a user’s timeline (consisting of tweets sent by a user and by other accounts that user follows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.9 Intro to Tweepy `Paginator`s: Getting More than One Page of Results (cont.)\n",
    "* Each Twitter API can return a maximum number of items per call\n",
    "    * known as a page of results\n",
    "* For more than one page of results, use a Tweepy `Paginator` to handle paging details\n",
    "* `Paginator` invokes a specified `Client` method and checks whether there is another page of results\n",
    "    * If so, the `Paginator` automatically calls the method again to get those results\n",
    "    * Continues (subject to the method’s rate limits) until there are no more results to process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.9.1 Determining an Account’s Followers  \n",
    "* Use a `Paginator` to invoke the `Client` object’s `get_users_followers` method\n",
    "* Calls the Twitter API’s method\n",
    "> `/2/users/:id/followers`\n",
    "* Returns these in groups of 100 by default\n",
    "* Can request up to 1000 at a time\n",
    "* We’ll grab 10 of NASA’s followers, five at a time, so we receive two pages of results\n",
    "* Create a list to store the followers’ Twitter user names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "followers = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a `Paginator`\n",
    "* `Paginator` to call `get_users_followers` for NASA’s account  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "paginator = tweepy.Paginator(\n",
    "   client.get_users_followers, nasa.data.id, max_results=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* arguments are the method to call and any arguments that should be passed to that method\n",
    "    * `client.get_users_followers` indicates that the `Paginator` will call the `client` object’s `get_users_followers` method, \n",
    "    * `nasa.data.id` — ID number (obtained in Section 12.8) of the NASA Twitter account for which we’ll get followers, and \n",
    "    * `max_results=5` — results per page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Results\n",
    "* Use the `Paginator` to get some followers\n",
    "    * `paginator.flatten(10)` initiates the call to `client.get_users_followers`\n",
    "    * `10` indicates number of results to obtain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for follower in paginator.flatten(limit=10):\n",
    "    followers.append(follower.username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Followers: AdamBracy83 AldairR38989312 BugginLol Carlosf91022160 enriqueLpezroj3 farzandadamizad lil_timmy44505 Lila_May22 MikazukSirius QP_SimonS\n"
     ]
    }
   ],
   "source": [
    "print('Followers:', \n",
    "    ' '.join(sorted(followers, key=lambda s: s.lower())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic Paging\n",
    "* `flatten` automatically “pages” through the results by making multiple calls to `client.get_users_followers` as necessary\n",
    "* `flatten` makes multiple pages appear to be a sequence of results\n",
    "* If you do not specify an argument to `flatten`, the `Paginator` attempts to get all of the account’s followers\n",
    "    * This could take significant time due to Twitter’s rate limits \n",
    "    * `/2/users/:id/followers` can return a maximum of 1000 followers at a time, and Twitter allows up to 15 calls every 15 minutes\n",
    "    * 15,000 followers every 15 minutes using Twitter’s free APIs\n",
    "    * At 60,000 followers per hour, it would take over 40 days to get all of NASA’s followers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.9.2 Determining Whom an Account Follows \n",
    "* `Client` object’s `get_users_following` method calls the Twitter API’s \n",
    "`/2/users/:id/following` method to get a list of Twitter users an account follows\n",
    "* Returns groups of 100 by default, but you can request up to 1000 at a time\n",
    "* Can call this method up to 15 times every 15 minutes\n",
    "* Get 10 accounts that NASA follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Following: Astro_Ayers astro_berrios astro_deniz astro_matthias Astro_Pam astro_watkins JimFree NASA_Gateway NASASpaceSci v_wyche\n"
     ]
    }
   ],
   "source": [
    "following = []\n",
    "\n",
    "paginator = tweepy.Paginator(\n",
    "    client.get_users_following, nasa.data.id, max_results=5)\n",
    "\n",
    "for user_followed in paginator.flatten(limit=10):\n",
    "    following.append(user_followed.username)\n",
    "\n",
    "print('Following:', \n",
    "      ' '.join(sorted(following, key=lambda s: s.lower())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 12.9.3 Getting a User’s Recent Tweets \n",
    "* `Client` method `get_users_tweets` returns a `tweepy.Response` containing tweets from a specified user\n",
    "* Calls the Twitter API’s `/2/users/:id/tweets` method\n",
    "* Returns the most recent 10 tweets but can between 5 and 100 at a time\n",
    "* Can return only an account’s 3200 most recent tweets\n",
    "* May call this method up to 1500 times every 15 minutes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 12.9.3 Getting a User’s Recent Tweets (cont.) \n",
    "* The `data` attribute of the `tweepy.Response` contains a list of the returned tweets\n",
    "    * Each object in that list has a dictionary `data` attribute containing the keys `'id'` and `'text'` for each tweet’s unique ID and its text\n",
    "* Display five tweets from the `@NASA` account using its ID number that we obtained previously: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NASA: RT @NASAArtemis: .@NASA will hold a media teleconference at 12:30pm ET on Sept. 23 to discuss yesterday's cryogenic test for the #Artemis I…\n",
      "\n",
      "NASA: @RollerRdr You can download the pictures in this gallery and have them printed. Scroll down for the link to full-resolution TIF and PNG versions of @NASAWebb images here: https://t.co/iyIetrnIxP\n",
      "\n",
      "NASA: Today marks the September equinox – the #FirstDayOfFall in the Northern Hemisphere and the first day of spring in the Southern Hemisphere – which occurs when both hemispheres see equal amounts of daylight: https://t.co/tvxoSjONUf\n",
      "\n",
      "How do you mark the changing seasons? https://t.co/pefGlH8Iyn\n",
      "\n",
      "NASA: @lvictorfaulkner @KILAGRIM @JHUAPL It won't hit the asteroid hard enough to knock it out of orbit, but our goal is to change the length of that orbit. That demonstrates that we can change the course of an asteroid.\n",
      "\n",
      "NASA: @carolineGx8 @JHUAPL Planetary defenders unite! Test your knowledge with our new and improved Planetary Defense quiz: https://t.co/CnxdS9t6qb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nasa_tweets = client.get_users_tweets(\n",
    "     id=nasa.data.id, max_results=5)\n",
    "\n",
    "for tweet in nasa_tweets.data:\n",
    "    print(f\"NASA: {tweet.data['text']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 12.9.3 Getting a User’s Recent Tweets (cont.)\n",
    "* We called the `get_users_tweets` method directly and used the keyword argument `max_results` to specify the number of tweets to retrieve\n",
    "* For more than the maximum number of tweets per call (100), use a `Paginator` to call `get_users_tweets` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grabbing Recent Tweets from Your Own Timeline\n",
    "* `Client` method `get_home_timeline` gets tweets from your home timeline\n",
    "    * your tweets and retweets, as well as tweets and retweets from the Twitter users you follow\n",
    "> `client.get_home_timeline()`\n",
    "* Calls Twitter’s `/2/users/:id/timelines/reverse_chronological` method \n",
    "* Returns up to 100 tweets by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 12.10 Searching Recent Tweets; Intro to Twitter v2 API Search Operators \n",
    "* `Client` method `search_recent_tweets` \n",
    "    * Returns tweets from the last seven days that match a query string you provide\n",
    "    * Calls Twitter method `/2/tweets/search/recent`, \n",
    "    * Returns a minimum of 10 tweets at a time (the default) but can return up to 100 (specified with keyword argument max_results)\n",
    "    * It’s possible that fewer than 10 tweets will match the specified query string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Function `print_tweets` from `tweetutilities.py`\n",
    "* Receives the results of a call to API method `search` and for each tweet displays the user’s `screen_name` and the tweet’s `text`. \n",
    "* If the tweet is not in English and the `tweet.lang` is not `'und'` (undefined), we’ll also translate the tweet to English  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweetutilities import print_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def print_tweets(tweets):\n",
    "    # translator to autodetect source language and return English\n",
    "    translator = GoogleTranslator(source='auto', target='en')\n",
    "\n",
    "    \"\"\"For each tweet in tweets, display the username of the sender\n",
    "    and tweet text. If the language is not English, translate the text \n",
    "    with the deep-translator library's GoogleTranslator.\"\"\"\n",
    "    for tweet, user in zip(tweets.data, tweets.includes['users']):\n",
    "        print(f'{user.username}:', end=' ')\n",
    "\n",
    "        if 'en' in tweet.lang:\n",
    "            print(f'{tweet.text}\\n')\n",
    "        elif 'und' not in tweet.lang: # translate to English first\n",
    "            print(f'\\n  ORIGINAL: {tweet.text}')\n",
    "            print(f'TRANSLATED: {translator.translate(tweet.text)}\\n')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching for Specific Words\n",
    "* Call `Client` object’s `search_recent_tweets` method to search for 10 recent tweets about the Webb Space Telescope\n",
    "* Returns a `Response` object in which the data attribute contains a list of matching tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = client.search_recent_tweets(\n",
    "    query='Webb Space Telescope', \n",
    "    expansions=['author_id'], tweet_fields=['lang']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `query` keyword argument specifies the query string containing your search criteria\n",
    "* Twitter returns only each tweet’s unique ID and text by default\n",
    "* `'lang'` is an additional field you may request via the `tweet_fields` parameter\n",
    "* Complete list of tweet fields\n",
    "> https://developer.twitter.com/en/docs/twitter-api/data-dictionary/object-model/tweet\n",
    "* The expansion `'author_id'` indicates that for each tweet, Twitter also should return the user JSON object for the user who sent the tweet—`id`, `name` and `username` by default\n",
    "* Tweepy places the expansion objects in the `Response`’s `includes` dictionary attribute\n",
    "    * For the `'author_id'` expansion, a list of tweet authors is stored with the key `'users'`\n",
    "    * Each tweet has a corresponding user in this list\n",
    "    * The following expression in line 8 of `print_tweets` creates tuples in which the first element represents a tweet and the second element represents the user object for the sender\n",
    "    > `zip(tweets.data, tweets.includes['users'])`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Display the tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yoyo_eomer: RT @uhd2020: Dying Star Captured from the James Webb Space Telescope https://t.co/2DBQpEJKVX\n",
      "\n",
      "Wara1329: RT @uhd2020: Jupiter from the James Webb Space Telescope https://t.co/VZP4hXOrmM\n",
      "\n",
      "dwtpauline: RT @uhd2020: Jupiter from the James Webb Space Telescope https://t.co/VZP4hXOrmM\n",
      "\n",
      "hemantK0303: RT @uhd2020: Dying Star Captured from the James Webb Space Telescope https://t.co/2DBQpEJKVX\n",
      "\n",
      "Rosiebreeze: RT @nytimes: On Wednesday, the James Webb Space Telescope provided some of our best views of Neptune in 30 years.\n",
      "https://t.co/ttBldkbW0l\n",
      "\n",
      "rhuyshie: RT @uhd2020: Dying Star Captured from the James Webb Space Telescope https://t.co/2DBQpEJKVX\n",
      "\n",
      "alanofkaneohe: RT @uhd2020: Jupiter from the James Webb Space Telescope https://t.co/VZP4hXOrmM\n",
      "\n",
      "ValantisL: RT @uhd2020: Dying Star Captured from the James Webb Space Telescope https://t.co/2DBQpEJKVX\n",
      "\n",
      "suuunantha: RT @uhd2020: Jupiter from the James Webb Space Telescope https://t.co/VZP4hXOrmM\n",
      "\n",
      "steeldawn2012: RT @nbcwashington: NASA released new glamour shots of our solar system's outermost planet. https://t.co/4Y7902IqdJ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_tweets(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching with Twitter v2 API Search Operators\n",
    "* Can use Twitter search operators in query strings to refine search results\n",
    "* Max query-string length is limited by your developer account type:\n",
    "    * For Essentials and Elevated accounts: up to 512 characters\n",
    "    * For Academic Research accounts: up to 1024 characters\n",
    "* Some operators are available only for Elevated accounts or higher\n",
    "* The Twitter v2 operators are categorized as **standalone** or **conjunction-required**\n",
    "    * **Standalone operators** can be used alone or combined with other operators in a query string\n",
    "    * **Conjunction-required operators** must be combined with at least one standalone operator in a query string\n",
    "* The following table shows several Twitter search operators, as well as logical AND, logical OR and logical negation capabilities\n",
    "    * parentheses can be used to group query-string subexpressions\n",
    "    * matching is performed using case-insensitive searching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Example&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; | Finds tweets containing |\n",
    "| --- | --- |\n",
    "| `python twitter` | Finds tweets containing `python` AND `twitter`. Spaces between query string terms and operators are implicitly treated as logical AND operations. In this query string, `python` and `twitter` are terms to search for—these are considered **standalone operators**.\n",
    "| `python OR twitter` \t| Finds tweets containing `python` `OR` `twitter` `OR` both. The logical `OR` operator is case-sensitive.\n",
    "| `planets -mars` \t| `-` (minus sign)—Finds tweets containing `planets` but not `mars`. The minus is the logical NOT operator and can be applied to any operator.\n",
    "| An emoji | Use emojis as standalone operators to find tweets containing those emojis. \n",
    "| `has:hashtags`, `has:links`, `has:mentions`, `has:media`, … | You can combine these **conjunction-required operators** with standalone operators to find tweets containing hashtags, links, mentions of other users, media and more. \n",
    "| `is:retweet`, `is:reply`, `is:verified`, … | You can combine these **conjunction-required operators** with standalone operators to determine whether a tweet is a retweet, a tweet is a reply, the sender is a verified Twitter account and more. \n",
    "| `place:\"New York City\"` | Finds tweets that were sent near `\"New York City\"`. Multiword places should be quoted as shown here. \n",
    "| `from:NASA` \t| Finds tweets from the account `@NASA`.\n",
    "| `to:NASA` \t| Finds tweets to the account `@NASA`. You also may use `to:id`, where `id` is the unique ID number of the user account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operator Documentation and Tutorial\n",
    "* All operators with examples of each  \n",
    "> https://developer.twitter.com/en/docs/twitter-api/tweets/search/integrate/build-a-query\n",
    "* Twitter’s tutorial on building high-quality Twitter v2 API query strings to obtain the targeted results\n",
    "> https://developer.twitter.com/en/docs/tutorials/building-high-quality-filters\n",
    "* Twitter online tool to help you build Twitter v2 API query strings\n",
    "> https://developer.twitter.com/apitools/query?query="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching for Tweets From NASA Containing Links\n",
    "* Use `from` and `has:links` operators to get recent tweets from `NASA` that contain hyperlinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = client.search_recent_tweets(\n",
    "    query='from:NASA has:links', \n",
    "    expansions=['author_id'], tweet_fields=['lang'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NASA: RT @NASAArtemis: .@NASA will hold a media teleconference at 12:30pm ET on Sept. 23 to discuss yesterday's cryogenic test for the #Artemis I…\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_tweets(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Searching for a Hashtag\n",
    "* Get tweets containing the hashtag `#metaverse`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tweets = client.search_recent_tweets(query='#metaverse', \n",
    "    expansions=['author_id'], tweet_fields=['lang'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kyusvl: RT @FantasyArenaNFT: @VitalikButerin thanks for every idea of the DAO, we are here developing thanks to you!  Check out this on @opensea ht…\n",
      "\n",
      "Yuypenchawee82: RT @HyperNation8: 🚀Join us through these 3 citizen welfare! \n",
      "The HyperNation will be the one and only city you will live in! 🏙️\n",
      "\n",
      "Follow @Hy…\n",
      "\n",
      "Uditha25: RT @SomeFi_Network: 1/🔥#SOMEFI AIRDROP IS LIVE NOW🔥\n",
      "\n",
      "All you need to do is complete extremely simple tasks to get amazing rewards.\n",
      "\n",
      "❗️How t…\n",
      "\n",
      "karugahvictor: \n",
      "  ORIGINAL: RT @Umair70603634: #nft #nftart #art #nfts #crypto #nftartist #digitalart #nftcommunity #nftcollector #cryptoart #ethereum #opensea #blockc…\n",
      "TRANSLATED: RT @Umair70603634: #nft #nftart #art #nfts #crypto #nftartist #digitalart #nftcommunity #nftcollector #cryptoart #ethereum #opensea #blockc…\n",
      "\n",
      "Nguyn7Quc: Join the Adamant Metanetwork Quests and claim your free rewards! https://t.co/z8qI1HIhQj  #adamantquests #adamantmetanetwork #metaverse\n",
      "\n",
      "yunes14000: RT @HyperNation8: 🚀Join us through these 3 citizen welfare! \n",
      "The HyperNation will be the one and only city you will live in! 🏙️\n",
      "\n",
      "Follow @Hy…\n",
      "\n",
      "Yuksel__Gonca: RT @HyperNation8: 🚀Join us through these 3 citizen welfare! \n",
      "The HyperNation will be the one and only city you will live in! 🏙️\n",
      "\n",
      "Follow @Hy…\n",
      "\n",
      "Yazici__Didar: RT @HyperNation8: 🚀Join us through these 3 citizen welfare! \n",
      "The HyperNation will be the one and only city you will live in! 🏙️\n",
      "\n",
      "Follow @Hy…\n",
      "\n",
      "Limasha5: RT @CryptoBlockEpic: 🥳To celebrate the reveal of @CryptoBlockEpic, we will give away 💵$10,000 worth prizes to our early supporters and prom…\n",
      "\n",
      "Ox_Lucky_Winx: RT @mt_tower: 😱 In just one month, #MTtower has 1️⃣5️⃣0️⃣0️⃣0️⃣ strong Followers on Twitter! \n",
      "\n",
      "🤝Thank you for your invaluable trust &amp; suppo…\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_tweets(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.11 Spotting Trends: Twitter Trends API\n",
    "**Note: At the time of this writing, Twitter had not yet migrated their Trending Topics APIs from v1.1 to v2. The v1.1 APIs used in this section are accessible only to Twitter Developer accounts with “Elevated” access and higher.**\n",
    "\n",
    "* If a topic **“goes viral,”** thousands or even millions of people could tweet about it\n",
    "* Twitter calls these **trending topics** and maintains lists of them worldwide\n",
    "* Via the Twitter v1.1 Trends API, you can get lists of locations with trending topics and lists of the top 50 trending topics for each location\n",
    "* To use the v1.1 APIs in Tweepy, initialize an object of class `OAuth2BearerHandler` with your bearer token, then create an `API` object that uses the `OAuth2BearerHandler` object to authenticate with Twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuth2BearerHandler(keys.bearer_token)\n",
    "\n",
    "api = tweepy.API(auth=auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.11.1 Places with Trending Topics \n",
    "* Tweepy `API`’s **`available_trends` method** calls Twitter’s [`trends/available`](https://developer.twitter.com/en/docs/trends/locations-with-trending-topics/api-reference/get-trends-available)  \n",
    "* Returns **list of dictionaries** representing locations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_trends = api.available_trends()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "467"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(available_trends)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Each element contains location’s `name`, `woeid` (**Yahoo! Where on Earth ID**) and more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Worldwide',\n",
       " 'placeType': {'code': 19, 'name': 'Supername'},\n",
       " 'url': 'http://where.yahooapis.com/v1/place/1',\n",
       " 'parentid': 0,\n",
       " 'country': '',\n",
       " 'woeid': 1,\n",
       " 'countryCode': None}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_trends[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Winnipeg',\n",
       " 'placeType': {'code': 7, 'name': 'Town'},\n",
       " 'url': 'http://where.yahooapis.com/v1/place/2972',\n",
       " 'parentid': 23424775,\n",
       " 'country': 'Canada',\n",
       " 'woeid': 2972,\n",
       " 'countryCode': 'CA'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_trends[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.11.1 Places with Trending Topics (cont.)\n",
    "* WOEID 1 represents **worldwide** \n",
    "* WOEID values for several landmarks, cities, states and continents\n",
    "\n",
    "| Place | WOEID | Place | WOEID |\n",
    "| --- | --- | --- | --- |\n",
    "| Statue of Liberty | 23617050 | Iguazu Falls | 468785\n",
    "| Los Angeles, CA | 2442047 | United States | 23424977\n",
    "| Washington, D.C. | 2514815 | North America | 24865672\n",
    "| Paris, France | 615702 | Europe | 24865675\n",
    "\n",
    "* Also can search for locations close to a **latitude** and **longitude** via the **Tweepy `API`’s `closest_trends` method**\n",
    "* Calls Twitter's [`trends/closest` method](https://developer.twitter.com/en/docs/trends/locations-with-trending-topics/api-reference/get-trends-closest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.11.2 Getting a List of Trending Topics \n",
    "* Via Tweepy `API`’s **`get_place_trends` method** \n",
    "* Calls **Twitter Trends API’s [`trends/place` method](https://developer.twitter.com/en/docs/trends/trends-for-location/api-reference/get-trends-place)**\n",
    "* Returns top 50 trending topics for the location \n",
    "* [Look up WOEIDs](http://www.woeidlookup.com) \n",
    "* Look up WOEID’s programmatically using **Yahoo!’s web services** via [Python libraries like `woeid`](https://github.com/Ray-SunR/woeid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worldwide Trending Topics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_trends = api.get_place_trends(id=1)  # list containing one dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **`'trends'` key** refers to a list of dictionaries representing each trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends_list = world_trends[0]['trends']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Each trend has **`name`**, **`url`**, **`promoted_content`** (whether it's an advertisement), **`query`** and **`tweet_volume`** keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': '村田兆治',\n",
       " 'url': 'http://twitter.com/search?q=%E6%9D%91%E7%94%B0%E5%85%86%E6%B2%BB',\n",
       " 'promoted_content': None,\n",
       " 'query': '%E6%9D%91%E7%94%B0%E5%85%86%E6%B2%BB',\n",
       " 'tweet_volume': 18966}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trends_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Today's Worldwide Trending Topics (cont.)\n",
    "* For **trends with more than 10,000 tweets**, the `tweet_volume` is the number of tweets; otherwise, it’s `None`\n",
    "* Filter the list so that it contains only trends with more than 10,000 tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends_list = [t for t in trends_list if t['tweet_volume']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sort the trends in _descending_ order by `tweet_volume`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends_list.sort(key=itemgetter('tweet_volume'), reverse=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Today's Worldwide Trending Topics (cont.)\n",
    "* Display names of the **top five trending topics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Browns\n",
      "Steelers\n",
      "#一緒に虹5thNT\n",
      "Stormzy\n",
      "秋分の日\n"
     ]
    }
   ],
   "source": [
    "for trend in trends_list[:5]:\n",
    "    print(trend['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New York City Trending Topics (WOEID `2459115`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_trends = api.get_place_trends(id=2459115)  # New York City WOEID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_list = nyc_trends[0]['trends']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_list = [t for t in nyc_list if t['tweet_volume']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_list.sort(key=itemgetter('tweet_volume'), reverse=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "judge\n",
      "Browns\n",
      "Steelers\n",
      "Dahmer\n",
      "Bond\n"
     ]
    }
   ],
   "source": [
    "for trend in nyc_list[:5]:\n",
    "    print(trend['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.11.3 Create a Word Cloud from Trending Topics\n",
    "* Visualize New York City’s trending topics with more than 10,000 tweets each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = {}  # dictionary to store trend names and volumes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for trend in nyc_list:\n",
    "    topics[trend['name']] = trend['tweet_volume']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.11.3 Create a Word Cloud from Trending Topics (cont.)\n",
    "* `prefer_horizontal=0.5` **suggests** that 50% of the words should be horizontal, but may ignore to fit content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width=1600, height=900,\n",
    "    prefer_horizontal=0.5, min_font_size=10, colormap='prism', \n",
    "    background_color='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = wordcloud.fit_words(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = wordcloud.to_file('TrendingTwitter.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Instructor note: You might need to duplicate the cell below (select it in the margin then press `c` to copy it and `v` to paste it), then execute the cell to see the new word cloud**\n",
    "* Depending on the number of trending topics, the word cloud may be sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![A word cloud generated from trending Twitter hashtags](./TrendingTwitter.png \"A word cloud generated from trending Twitter hashtags\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "&copy;1992&ndash;2020 by Pearson Education, Inc. All Rights Reserved. This content is based on Chapter 5 of the book [**Intro to Python for Computer Science and Data Science: Learning to Program with AI, Big Data and the Cloud**](https://amzn.to/2VvdnxE).\n",
    "\n",
    "DISCLAIMER: The authors and publisher of this book have used their \n",
    "best efforts in preparing the book. These efforts include the \n",
    "development, research, and testing of the theories and programs \n",
    "to determine their effectiveness. The authors and publisher make \n",
    "no warranty of any kind, expressed or implied, with regard to these \n",
    "programs or to the documentation contained in these books. The authors \n",
    "and publisher shall not be liable in any event for incidental or \n",
    "consequential damages in connection with, or arising out of, the \n",
    "furnishing, performance, or use of these programs.                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.12 Cleaning/Preprocessing Tweets for Analysis\n",
    "* **Data cleaning** is one of data scientists' most common tasks \n",
    "* Some NLP tasks for normalizing tweets\n",
    "    * Converting all text to the same case\n",
    "    * Removing `#` from hashtags, `@`-mentions, duplicates, hashtags\n",
    "    * Removing excess whitespace, punctuation, **stop words**, URLs\n",
    "    * Removing `RT` (retweet) and `FAV` (favorite) \n",
    "    * **Stemming** and **lemmatization**\n",
    "    * **Tokenization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [**tweet-preprocessor**](https://github.com/s/preprocessor) Library and TextBlob Utility Functions\n",
    "* tweet-preprocessor can automatically remove any combination of\n",
    "\t* URLs\n",
    "\t* `@`-mentions (like `@nasa`)\n",
    "\t* hashtags (like `#mars`)\n",
    "\t* Twitter reserved words (like, `RT` for retweet and `FAV` for favorite, which is similar to a “like” on other social networks)\n",
    "\t* emojis (all or just smileys) \n",
    "\t* numbers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tweet-preprocessor Constants for Cleaning Options\n",
    "\n",
    "| Option\t| Option constant\n",
    "| :---\t| :---\n",
    "| @-Mentions (e.g., `@nasa`)\t| `OPT.MENTION` \n",
    "| Emoji\t| `OPT.EMOJI` \n",
    "| Hashtag (e.g., `#mars`)\t| `OPT.HASHTAG` \n",
    "| Number\t| `OPT.NUMBER` \n",
    "| Reserved Words (`RT` and `FAV`)\t| `OPT.RESERVED` \n",
    "| Smiley\t| `OPT.SMILEY` \n",
    "| URL\t| `OPT.URL` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing tweet-preprocessor\n",
    ">```python\n",
    "pip install tweet-preprocessor\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning a Tweet \n",
    "* Remove reserved word (RT for \"retweet\") and a URL\n",
    "* The tweet-preprocessor library’s module name is **`preprocessor`** and they recommend importing as **`p`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessor as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.set_options(p.OPT.URL, p.OPT.RESERVED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_text = 'RT A sample retweet with a URL https://nasa.gov'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.clean(tweet_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "&copy;1992&ndash;2020 by Pearson Education, Inc. All Rights Reserved. This content is based on Chapter 5 of the book [**Intro to Python for Computer Science and Data Science: Learning to Program with AI, Big Data and the Cloud**](https://amzn.to/2VvdnxE).\n",
    "\n",
    "DISCLAIMER: The authors and publisher of this book have used their \n",
    "best efforts in preparing the book. These efforts include the \n",
    "development, research, and testing of the theories and programs \n",
    "to determine their effectiveness. The authors and publisher make \n",
    "no warranty of any kind, expressed or implied, with regard to these \n",
    "programs or to the documentation contained in these books. The authors \n",
    "and publisher shall not be liable in any event for incidental or \n",
    "consequential damages in connection with, or arising out of, the \n",
    "furnishing, performance, or use of these programs.                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 12.13 Twitter Streaming API\n",
    "* Your app can receive tweets as they occur in real-time\n",
    "* Based on the Twitter Statistics page at [InternetLiveStats.com](http://www.internetlivestats.com/twitter-statistics/)\n",
    "    * over 10,000 tweets per second \n",
    "    * approximately 880 million tweets per day\n",
    "* Most developer accounts are subject to a **tweet cap** — a maximum number of tweets per month that an account’s Twitter apps can acquire using the Twitter APIs\n",
    "    * 500,000 for Essentials accounts \n",
    "    * two million for Elevated accounts\n",
    "    * academic research and paid accounts can get more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.13.1 Creating a Subclass of `StreamListener` \n",
    "* A stream uses a **persistent** connection to **push** tweets to your app\n",
    "* Streaming rate varies tremendously, based on search criteria specified with Tweepy **`StreamRule`** objects\n",
    "* Twitter uses all the `StreamRule`s you set to find tweets, including `StreamRule`s you’ve set previously\n",
    "* You may want to delete existing `StreamRule`s before creating new ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.13.1 Creating a Subclass of `StreamListener` (cont.)\n",
    "* Create a subclass of Tweepy’s `StreamingClient` class to process the tweet stream\n",
    "* Tweepy calls the methods on an object of this class as it receives each new tweet (or other message, such as an error) from Twitter\n",
    "    * `on_connect(self)` is called when your app successfully connects to the Twitter stream\n",
    "    * `on_respone(self, response)` is called when a response arrives from the Twitter stream—`response` parameter is a Tweepy `StreamResponse` named tuple object containing the tweet data, any expansion objects you requested and more\n",
    "* `StreamingClient` already defines these and other \"on_\" methods \n",
    "* Override only the methods your app needs\n",
    "* `StreamingClient` methods\n",
    "> https://docs.tweepy.org/en/latest/streamingclient.html  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class `TweetListener`\n",
    "`StreamingClient` subclass `TweetListener` is defined in `tweetlistener.py`\n",
    "\n",
    "```python\n",
    "# tweetlistener.py\n",
    "\"\"\"StreamingClient subclass that processes tweets as they arrive.\"\"\"\n",
    "from deep_translator import GoogleTranslator\n",
    "import tweepy\n",
    "\n",
    "class TweetListener(tweepy.StreamingClient):\n",
    "    \"\"\"Handles incoming Tweet stream.\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Class `TweetListener`: `__init__` Method \n",
    "* called when you create a new `TweetListener` object\n",
    "* `bearer_token` is used to authenticate with Twitter\n",
    "* `limit` parameter is the number of tweets to process\n",
    "* Line 11: instance variable to track the number of tweets processed so far\n",
    "* Line 12: constant to store the limit\n",
    "* `GoogleTranslator` object for translating tweets into English\n",
    "* Line 17 passes the `bearer_token` to the superclass’s `__init__`\n",
    "\n",
    "```python\n",
    "    def __init__(self, bearer_token, limit=10):\n",
    "        \"\"\"Create instance variables for tracking number of tweets.\"\"\"\n",
    "        self.tweet_count = 0\n",
    "        self.TWEET_LIMIT = limit\n",
    "        \n",
    "        # GoogleTranslator object for translating tweets to English \n",
    "        self.translator = GoogleTranslator(source='auto', target='en')\n",
    "\n",
    "        super().__init__(bearer_token, wait_on_rate_limit=True)  \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class `TweetListener`: `on_connect` Method \n",
    "* Called when your app successfully connects to the Twitter stream\n",
    "\n",
    "```python\n",
    "    def on_connect(self):\n",
    "        \"\"\"Called when your connection attempt is successful, enabling \n",
    "        you to perform appropriate application tasks at that point.\"\"\"\n",
    "        print('Connection successful\\n')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class `TweetListener`: `on_response` Method \n",
    "* Called by when each tweet arrives\n",
    "* second parameter is a Tweepy `StreamResponse` named tuple object containing:\n",
    "    * `data` — the tweet’s attributes\n",
    "    * `includes` — any requested expansion objects\n",
    "    * `errors` — any errors that occurred\n",
    "    * `matching_rules` — `StreamRules` that the returned tweet matched\n",
    "* This example uses an expansion to include in the `StreamResponse` the user JSON object for each tweet’s sender\n",
    "    * Twitter also returns user objects for accounts mentioned in the tweet’s text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    def on_response(self, response):\n",
    "        \"\"\"Called when Twitter pushes a new tweet to you.\"\"\"\n",
    "        \n",
    "        try:\n",
    "            # get username of user who sent the tweet\n",
    "            username = response.includes['users'][0].username\n",
    "            print(f'Screen name: {username}')\n",
    "            print(f'   Language: {response.data.lang}')\n",
    "            print(f' Tweet text: {response.data.text}')\n",
    "\n",
    "            if response.data.lang != 'en' and response.data.lang != 'und':\n",
    "                english = self.translator.translate(response.data.text)\n",
    "                print(f' Translated: {english}')\n",
    "\n",
    "            print()\n",
    "            self.tweet_count += 1 \n",
    "        except Exception as e:\n",
    "            print(f'Exception occured: {e}')\n",
    "            self.disconnect()\n",
    "            \n",
    "        # if TWEET_LIMIT is reached, terminate streaming\n",
    "        if self.tweet_count == self.TWEET_LIMIT:\n",
    "            self.disconnect()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Line 29 gets the sender’s username\n",
    "    * List element 0 of `response.includes['users']` contains the tweet sender’s user object\n",
    "    * Subsequent elements would contain accounts mentioned in the tweet\n",
    "* Lines 30–32 display the tweet sender’s `username`, the tweet’s language (`lang`) and the tweet’s `text`\n",
    "* If necessary, lines 34–36 translate the tweet to English and display it\n",
    "* Line 39 increments `self.tweet_count`\n",
    "* Lines 45–46 determine whether to terminate streaming. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 12.13.2 Initiating Stream Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "import keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Creating a TweetListener \n",
    "* `StreamingClient` subclass `TweetListener` manages the connection to the Twitter stream and receives and processes the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tweetlistener import TweetListener\n",
    "\n",
    "tweet_listener = TweetListener(\n",
    "    bearer_token=keys.bearer_token, limit=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Redirecting the Standard Error Stream to the Standard Output Stream\n",
    "* When `StreamingClient` subclass’s `disconnect` method is called to terminate the tweet stream, the method sends the following message to `sys.stderr` which is not synchronized with the standard output stream\n",
    "> `Stream connection closed by Twitter`\n",
    "* Sometimes causes the preceding message to be interspersed with other messages that this app sends to the standard output stream\n",
    "* To prevent this, redirect the standard error stream to the standard output stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.stderr = sys.stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Deleting Existing Stream Rules\n",
    "* Twitter uses all the `StreamRule`s you’ve specified previously to filter the tweets it pushes to your app\n",
    "* Twitter does not automatically remove your `StreamRule`s after you terminate the tweet stream\n",
    "* If your app filters the tweet stream with different rules each time you run it, you should delete any existing `StreamRule`s before creating new ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "* Get the `StreamRule`s by calling your `StreamingClient`’s `get_rules` method\n",
    "    * `Response`’s `data` attribute contains a `list` of `StreamRule`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rules = tweet_listener.get_rules().data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "* Get the rule IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rule_ids = [rule.id for rule in rules]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "* Call `StreamingClient`’s `delete_rules` method with a list of rule IDs to delete\n",
    "    * response contains a `'summary'` dictionary with information about the number of deleted rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(data=None, includes={}, errors=[], meta={'sent': '2022-09-24T18:17:59.745Z', 'summary': {'deleted': 1, 'not_deleted': 0}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_listener.delete_rules(rule_ids)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Creating and Adding a Stream Rule\n",
    "* Create a rule to filter the live tweet stream looking for tweets about football\n",
    "* Then, add the rule\n",
    "    * `add_rules`’ Response contains a `'summary'` dictionary with information about the `StreamRule` you set and whether it was valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filter_rule = tweepy.StreamRule('football')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(data=[StreamRule(value='football', tag=None, id='1573738534137221120')], includes={}, errors=[], meta={'sent': '2022-09-24T18:18:01.090Z', 'summary': {'created': 1, 'not_created': 0, 'valid': 1, 'invalid': 0}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_listener.add_rules(filter_rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Starting the Tweet Stream\n",
    "* `StreamingClient`'s `filter` method begins streaming \n",
    "    * `expansions` argument indicates that we’d like the response for each tweet to include the sender’s user JSON object\n",
    "    * `tweet_fields` argument indicates that the tweet’s language should be included in the responses tweet JSON object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tweet_listener.filter( \n",
    "    expansions=['author_id'], tweet_fields=['lang'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Asynchronous vs. Synchronous Streams\n",
    "* Tweepy supports asynchronous tweet streams by creating a subclass of `AsyncStreamingClient`\n",
    "* Allows your application to continue executing while your listener waits to receive tweets\n",
    "* Convenient in GUI applications, so users can continue interacting with other parts of the application while tweets arrive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "&copy;1992&ndash;2020 by Pearson Education, Inc. All Rights Reserved. This content is based on Chapter 5 of the book [**Intro to Python for Computer Science and Data Science: Learning to Program with AI, Big Data and the Cloud**](https://amzn.to/2VvdnxE).\n",
    "\n",
    "DISCLAIMER: The authors and publisher of this book have used their \n",
    "best efforts in preparing the book. These efforts include the \n",
    "development, research, and testing of the theories and programs \n",
    "to determine their effectiveness. The authors and publisher make \n",
    "no warranty of any kind, expressed or implied, with regard to these \n",
    "programs or to the documentation contained in these books. The authors \n",
    "and publisher shall not be liable in any event for incidental or \n",
    "consequential damages in connection with, or arising out of, the \n",
    "furnishing, performance, or use of these programs.                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.14 Tweet Sentiment Analysis \n",
    "* Political researchers might use during elections to understand how people feel about specific politicians and issues, and **how they're likely to vote**\n",
    "* Companies might use to see what people are saying about their products and competitors’ products\n",
    "* Script `sentimentlistener.py` checks sentiment on a specified topic for a specified number of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run sentimentlistener.py football 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:#AAA; background-color:#AAA;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Class `SentimentListener`: Imports \n",
    "* Import the keys.py file and the libraries used throughout the script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "```python\n",
    "# sentimentlisener.py\n",
    "\"\"\"Script that searches for tweets that match a search string\n",
    "and tallies the number of positive, neutral and negative tweets.\"\"\"\n",
    "import keys\n",
    "import preprocessor as p \n",
    "import sys\n",
    "from textblob import TextBlob\n",
    "import tweepy\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class `SentimentListener`: `__init__` Method\n",
    "* Receives:\n",
    "    * `bearer_token` for authentication\n",
    "    * `sentiment_dict` dictionary in which we’ll keep track of the tweet sentiments\n",
    "    * `topic` we’re searching for so we can ensure that it appears in the tweet text  \n",
    "    * `limit` of tweets to process (not including the ones we eliminate)\n",
    "* Each of these is stored in the current `SentimentListener` object (`self`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class SentimentListener(tweepy.StreamingClient):\n",
    "    \"\"\"Handles incoming Tweet stream.\"\"\"\n",
    "\n",
    "    def __init__(self, bearer_token, sentiment_dict, topic, limit=10):\n",
    "        \"\"\"Configure the SentimentListener.\"\"\"\n",
    "        self.sentiment_dict = sentiment_dict\n",
    "        self.tweet_count = 0\n",
    "        self.topic = topic\n",
    "        self.TWEET_LIMIT = limit\n",
    "\n",
    "        # set tweet-preprocessor to remove URLs/reserved words\n",
    "        p.set_options(p.OPT.URL, p.OPT.RESERVED) \n",
    "        super().__init__(bearer_token, wait_on_rate_limit=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method `on_response `\n",
    "* If the tweet is not a retweet (line 28):\n",
    "    * Line 29 gets and cleans the tweet’s text \n",
    "    * Lines 32–33 skip the tweet if it does not contain `topic` in the tweet text\n",
    "    * Lines 36–45 use a `TextBlob` to check the tweet’s sentiment and update the `sentiment_dict` accordingly\n",
    "    * Line 48 gets the sender’s `username` from `response.includes['users']` — we’ll use an expansion to include this user object \n",
    "    * Line 49 prints the tweet text preceded by `+` for positive sentiment, a space for neutral sentiment or `-` for negative sentiment\n",
    "    * Line 51 increments the `tweet_count`, and lines 54–55 check whether the app should disconnect from the tweet stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def on_response(self, response):\n",
    "        \"\"\"Called when Twitter pushes a new tweet to you.\"\"\"\n",
    "\n",
    "        # if the tweet is not a retweet\n",
    "        if not response.data.text.startswith('RT'):\n",
    "            text = p.clean(response.data.text) # clean the tweet\n",
    "\n",
    "            # ignore tweet if the topic is not in the tweet text\n",
    "            if self.topic.lower() not in text.lower():\n",
    "                return\n",
    "\n",
    "            # update self.sentiment_dict with the polarity\n",
    "            blob = TextBlob(text)\n",
    "            if blob.sentiment.polarity > 0:\n",
    "                sentiment = '+'\n",
    "                self.sentiment_dict['positive'] += 1 \n",
    "            elif blob.sentiment.polarity == 0:\n",
    "                sentiment = ' '\n",
    "                self.sentiment_dict['neutral'] += 1 \n",
    "            else:\n",
    "                sentiment = '-'\n",
    "                self.sentiment_dict['negative'] += 1 \n",
    "\n",
    "            # display the tweet\n",
    "            username = response.includes['users'][0].username\n",
    "            print(f'{sentiment} {username}: {text}\\n')\n",
    "\n",
    "            self.tweet_count += 1 # track number of tweets processed\n",
    "\n",
    "            # if TWEET_LIMIT is reached, terminate streaming\n",
    "            if self.tweet_count == self.TWEET_LIMIT:\n",
    "                self.disconnect()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Application\n",
    "* The main application is defined in the function `main` (lines 57–87; discussed after the code), which is called by lines 90–91 when you execute the file as a script\n",
    "* `sentimentlistener.py` also can be imported into IPython or other modules to use class `SentimentListener` as we did with `TweetListener`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def main():\n",
    "    # get search term and number of tweets\n",
    "    search_key = sys.argv[1]\n",
    "    limit = int(sys.argv[2]) # number of tweets to tally\n",
    "\n",
    "    # set up the sentiment dictionary\n",
    "    sentiment_dict = {'positive': 0, 'neutral': 0, 'negative': 0}\n",
    "\n",
    "    # create the StreamingClient subclass object\n",
    "    sentiment_listener = SentimentListener(keys.bearer_token, \n",
    "        sentiment_dict, search_key, limit)\n",
    "\n",
    "    # redirect sys.stderr to sys.stdout\n",
    "    sys.stderr = sys.stdout\n",
    "\n",
    "    # delete existing stream rules\n",
    "    rules = sentiment_listener.get_rules().data\n",
    "    rule_ids = [rule.id for rule in rules]\n",
    "    sentiment_listener.delete_rules(rule_ids)    \n",
    "\n",
    "    # create stream rule\n",
    "    sentiment_listener.add_rules(\n",
    "        tweepy.StreamRule(f'{search_key} lang:en'))\n",
    "\n",
    "    # start filtering English tweets containing search_key\n",
    "    sentiment_listener.filter(expansions=['author_id'])\n",
    "\n",
    "    print(f'Tweet sentiment for \"{search_key}\"')\n",
    "    print('Positive:', sentiment_dict['positive'])\n",
    "    print(' Neutral:', sentiment_dict['neutral'])\n",
    "    print('Negative:', sentiment_dict['negative'])\n",
    "\n",
    "# call main if this file is executed as a script\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In `main`:\n",
    "    * Lines 59–60 get the command-line arguments\n",
    "    * Line 63 creates the `sentiment_dict` dictionary that keeps track of the tweet sentiments\n",
    "    * Lines 66–67 create the `SentimentListener` \n",
    "    * Line 70 redirects the standard error stream to the standard output stream\n",
    "    * Lines 73–75 delete any existing `StreamRule`s\n",
    "    * Lines 78–79 create a new `StreamRule` that searches for English (`lang:en`) tweets that match the `search_key`\n",
    "    * Line 82 starts the stream — `expansions` indicates that we’d like Twitter to include the tweet sender’s user object in the response\n",
    "    * Lines 84–87 display the sentiment report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "&copy;1992&ndash;2020 by Pearson Education, Inc. All Rights Reserved. This content is based on Chapter 5 of the book [**Intro to Python for Computer Science and Data Science: Learning to Program with AI, Big Data and the Cloud**](https://amzn.to/2VvdnxE).\n",
    "\n",
    "DISCLAIMER: The authors and publisher of this book have used their \n",
    "best efforts in preparing the book. These efforts include the \n",
    "development, research, and testing of the theories and programs \n",
    "to determine their effectiveness. The authors and publisher make \n",
    "no warranty of any kind, expressed or implied, with regard to these \n",
    "programs or to the documentation contained in these books. The authors \n",
    "and publisher shall not be liable in any event for incidental or \n",
    "consequential damages in connection with, or arising out of, the \n",
    "furnishing, performance, or use of these programs.                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.15 Geocoding and Mapping\n",
    "* Collect streaming tweets, then plot their locations on an interactive map\n",
    "* **Twitter disables precise location info (latitude/longitude) by default** (users must opt in to allowing Twitter to track locations) \n",
    "* Large percentage include the user’s home location information\n",
    "    * Sometimes invalid or fictitious \n",
    "* Map markers will show the sender's `location` and tweet text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### [**geopy** library](https://github.com/geopy/geopy)\n",
    "* Setup in Section 12.6\n",
    "* **Geocoding**&mdash;translate locations into **latitude** and **longitude**\n",
    "* **geopy** supports dozens of **geocoding web services**, many with **free or lite tiers**\n",
    "* We’ll use **OpenMapQuest geocoding service** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenMapQuest Geocoding API\n",
    "* Sign-up instructions in Section 12.6\n",
    "* Convert locations, such as **Boston, MA** into their **latitudes** and **longitudes**, such as **42.3602534** and **-71.0582912**, for plotting on maps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [**folium library**](https://github.com/python-visualization/folium) and Leaflet.js JavaScript Mapping Library\n",
    "* Setup in Section 12.6\n",
    "* For maps — uses **Leaflet.js JavaScript mapping library** to display maps in a web page \n",
    "* Folium save as HTML files that you can view in your web browser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 12.15.1 Getting and Mapping the Tweets\n",
    "* We’ll use utility functions from our **`tweetutilities.py`** file and class **`LocationListener`** in **`locationlistener.py`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collections Required By LocationListener\n",
    "* a list (`tweets`) to store the data from the tweets we collect \n",
    "* a dictionary (`counts`) to track the total number of tweets we collect and the number that have location data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [] \n",
    "\n",
    "counts = {'total_tweets': 0, 'locations': 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the LocationListener \n",
    "* Collect 50 tweets about `'football'`\n",
    "* `LocationListener` will use utility function `get_tweet_content` (located in `tweetutilities.py`; discussed in Section 12.15.2) to place in a dictionary the `username`, tweet `text` and user `location` from each tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keys\n",
    "\n",
    "import tweepy\n",
    "\n",
    "from locationlistener import LocationListener\n",
    "\n",
    "location_listener = LocationListener(\n",
    "    keys.bearer_token, counts_dict=counts, tweets_list=tweets,\n",
    "    topic='football', limit=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Redirect sys.stderr to sys.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.stderr = sys.stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete Existing StreamRules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = location_listener.get_rules().data\n",
    "\n",
    "rule_ids = [rule.id for rule in rules]\n",
    "\n",
    "location_listener.delete_rules(rule_ids)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a StreamRule\n",
    "* Rule to get tweets in English (`lang:en`) about football "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_listener.add_rules(\n",
    "    tweepy.StreamRule('football lang:en'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure and Start the Stream of Tweets\n",
    "* start streaming the tweets\n",
    "    * expansion `'author_id'` gets information about the user who sent the tweet, including the `username`\n",
    "    * `user_fields` argument specifies that the user information should include the account’s `'location'` \n",
    "    * `tweet_fields` argument specifies additional information to include with each tweet—in this case, the tweet’s `language`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_listener.filter(expansions=['author_id'], \n",
    "    user_fields=['location'], tweet_fields=['lang'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the Location Statistics\n",
    "* check how many tweets we processed, how many had locations and the percentage that had locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In [14]: counts['total_tweets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In [15]: counts['locations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In [16]: print(f'{counts[\"locations\"] / counts[\"total_tweets\"]:.1%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geocoding the Locations\n",
    "* Use `get_geocodes` utility function (from `tweetutilities.py`; discussed in Section 12.15.2) to geocode the location of each tweet stored in the list of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweetutilities import get_geocodes\n",
    "\n",
    "bad_locations = get_geocodes(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For each tweet with a valid location, the `get_geocodes` function adds the new keys `'latitude'` and `'longitude'` to that tweet’s dictionary in the `tweets` list — these will be used to plot map markers on our interactive map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the Bad Location Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{bad_locations / counts[\"locations\"]:.1%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the Data\n",
    "* Before we plot the tweet locations on a map, let’s use a pandas `DataFrame` to clean the data\n",
    "* When you create a * DataFrame* from the `tweets` list, it will contain the value `NaN` for the `'latitude'` and `'longitude'` of any tweet that does not have a valid location\n",
    "* `NaN` cannot be plotted on a map, so remove any rows containing `NaN` by calling the `DataFrame`’s `dropna` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Map with Folium\n",
    "Create a folium Map on which we’ll plot the tweet locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usmap = folium.Map(location=[39.8283, -98.5795], \n",
    "    tiles='Stamen Terrain', zoom_start=5, detect_retina=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `location` keyword argument specifies a sequence containing latitude and longitude coordinates for the **map’s center point** \n",
    "    * The values in this snippet are the **geographic center of the continental United States**\n",
    "    * In many places worldwide, the term `'football'` describes the sport we call soccer in the U.S., so some of the tweets we plot may be outside the U.S\n",
    "    * You can zoom using the **+** and **–** buttons at the map’s top-left, or you can dragging the map with the mouse (that is, pan) to see anywhere in the world\n",
    "*  `zoom_start` keyword argument specifies the map’s initial zoom level, lower values show more of the world\n",
    "* `detect_retina` keyword argument enables folium to detect high-resolution screens to use higher-resolution maps from `OpenStreetMap.org`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Popup Markers for the Tweet Locations\n",
    "* Create `folium` `Popup` objects containing each tweet’s text and add them to the `Map`\n",
    "* `DataFrame` method `itertuples` creates a named tuple from each row containing properties corresponding to each `DataFrame` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in df.itertuples():\n",
    "    text = ': '.join([t.username, t.text])\n",
    "    popup = folium.Popup(text, parse_html=True)\n",
    "    marker = folium.Marker((t.latitude, t.longitude), \n",
    "                           popup=popup)\n",
    "    marker.add_to(usmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Creates a string (`text`) containing the user’s `username` and tweet `text` \n",
    "* Creates a `folium` `Popup` to display the `text`\n",
    "* Creates a `folium` `Marker`\n",
    "    * tuple to specify the `Marker`’s latitude and longitude\n",
    "    * `popup` keyword argument associates the tweet’s `Popup` object with the new `Marker`\n",
    "* Calls the `Marker`’s `add_to` method to specify the `Map` that will display the `Marker`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Map\n",
    "* Call the `Map`’s `save` method to store the map in an HTML file, which you can then double-click to open in your web browser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "usmap.save('tweet_map.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usmap # displays the map in the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.15.2 Utility Functions in `tweetutilities.py` \n",
    "### `get_tweet_content` Utility Function \n",
    "* Receives a **`StreamResponse` object (`response`)** and creates a **dictionary** containing the **tweet’s `username`, `text` and `location`**\n",
    "\n",
    "```python\n",
    "def get_tweet_content(response):\n",
    "    \"\"\"Return dictionary with data from tweet.\"\"\"\n",
    "    fields = {}\n",
    "    fields['username'] = response.includes['users'][0].username\n",
    "    fields['text'] = response.data.text\n",
    "    fields['location'] = response.includes['users'][0].location\n",
    "\n",
    "    return fields\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `get_geocodes` Utility Function \n",
    "* Receives a list of dictionaries containing tweets and **geocodes their locations**\n",
    "* If geocoding is successful for a tweet, adds the **latitude** and **longitude** to the tweet’s **dictionary in `tweet_list`**\n",
    "* Requires class **`OpenMapQuest`** from the **geopy module**\n",
    "\n",
    "```python\n",
    "from geopy import OpenMapQuest\n",
    "```\n",
    "\n",
    "```python\n",
    "def get_geocodes(tweet_list):\n",
    "    \"\"\"Get the latitude and longitude for each tweet's location.\n",
    "    Returns the number of tweets with invalid location data.\"\"\"\n",
    "    print('Getting coordinates for tweet locations...')\n",
    "    geo = OpenMapQuest(api_key=keys.mapquest_key)  # geocoder\n",
    "    bad_locations = 0  \n",
    "\n",
    "    for tweet in tweet_list:\n",
    "        processed = False\n",
    "        delay = .1  # used if OpenMapQuest times out to delay next call\n",
    "        while not processed:\n",
    "            try:  # get coordinates for tweet['location']\n",
    "                geo_location = geo.geocode(tweet['location'])\n",
    "                processed = True\n",
    "            except:  # timed out, so wait before trying again\n",
    "                print('OpenMapQuest service timed out. Waiting.')\n",
    "                time.sleep(delay)\n",
    "                delay += .1\n",
    "\n",
    "        if geo_location:  \n",
    "            tweet['latitude'] = geo_location.latitude\n",
    "            tweet['longitude'] = geo_location.longitude\n",
    "        else:  \n",
    "            bad_locations += 1  # tweet['location'] was invalid\n",
    "    \n",
    "    print('Done geocoding')\n",
    "    return bad_locations\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `get_geocodes` Utility Function (cont.)\n",
    "* Creates the **`OpenMapQuest` object** we’ll use to geocode locations\n",
    "* Initializes **`bad_locations`** which we use to keep track of the number of invalid locations in the tweet objects we collected\n",
    "* Attempts to **geocode the current tweet’s location**\n",
    "* Prints a message that it’s done geocoding and returns the `bad_locations` value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.15.3 Class `LocationListener`\n",
    "```python\n",
    "# locationlistener.py\n",
    "\"\"\"Receives tweets matching a search string and stores a list of\n",
    "dictionaries containing each tweet's username/text/location.\"\"\"\n",
    "import tweepy\n",
    "from tweetutilities import get_tweet_content\n",
    "\n",
    "class LocationListener(tweepy.StreamingClient):\n",
    "    \"\"\"Handles incoming Tweet stream to get location data.\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    def __init__(self, bearer_token, counts_dict, \n",
    "                 tweets_list, topic, limit=10):\n",
    "        \"\"\"Configure the LocationListener.\"\"\"\n",
    "        self.tweets_list = tweets_list\n",
    "        self.counts_dict = counts_dict\n",
    "        self.topic = topic\n",
    "        self.TWEET_LIMIT = limit\n",
    "        super().__init__(bearer_token, wait_on_rate_limit=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    def on_response(self, response):\n",
    "        \"\"\"Called when Twitter pushes a new tweet to you.\"\"\"\n",
    "\n",
    "        # get each tweet's username, text and location\n",
    "        tweet_data = get_tweet_content(response)  \n",
    "\n",
    "        # ignore retweets and tweets that do not contain the topic\n",
    "        if (tweet_data['text'].startswith('RT') or\n",
    "            self.topic.lower() not in tweet_data['text'].lower()):\n",
    "            return\n",
    "\n",
    "        self.counts_dict['total_tweets'] += 1 # it's an original tweet\n",
    "\n",
    "        # ignore tweets with no location \n",
    "        if not tweet_data.get('location'):  \n",
    "            return\n",
    "\n",
    "        self.counts_dict['locations'] += 1 # user account has location\n",
    "        self.tweets_list.append(tweet_data) # store the tweet\n",
    "        print(f\"{tweet_data['username']}: {tweet_data['text']}\\n\")\n",
    "        \n",
    "        # if TWEET_LIMIT is reached, terminate streaming\n",
    "        if self.counts_dict['locations'] == self.TWEET_LIMIT:\n",
    "            self.disconnect()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.15.3 Class `LocationListener` (cont.)\n",
    "* `__init__` receives \n",
    "    * the `bearer_token` \n",
    "    * the number of tweets to process (`limit`)\n",
    "    * `counts` dictionary that we use to keep track of the total number of tweets processed\n",
    "    * `tweet_list` in which we store the dictionaries returned by the `get_tweet_content` utility function\n",
    "    * a string representing the topic so we can confirm that its text is contained in the tweet text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.15.3 Class `LocationListener` (cont.)\n",
    "* In method `on_response`\n",
    "   * Line 23 calls `get_tweet_content` to get each tweet’s screen name, text and location.\n",
    "    * Lines 26–28 ignore the tweet if it is a retweet or if the text does not include the topic we’re searching for\n",
    "    * Line 30 adds 1 to the value of the `'total_tweets'` key in the `counts` dictionary to track the number of original tweets\n",
    "    * Lines 33–34 ignore tweets that have no location data\n",
    "    * Line 36 adds 1 to the value of the `counts` dictionary’s `'locations'` key to indicate that we found a tweet with a location\n",
    "    * Line 37 appends the `tweet_data` dictionary to the `tweets_list`\n",
    "    * Line 38 displays the tweet’s screen name and tweet text so you can see that the app is making progress\n",
    "    * Lines 41–42 check whether the `TWEET_LIMIT` has been reached, and if so, disconnect from the stream."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "&copy;1992&ndash;2020 by Pearson Education, Inc. All Rights Reserved. This content is based on Chapter 5 of the book [**Intro to Python for Computer Science and Data Science: Learning to Program with AI, Big Data and the Cloud**](https://amzn.to/2VvdnxE).\n",
    "\n",
    "DISCLAIMER: The authors and publisher of this book have used their \n",
    "best efforts in preparing the book. These efforts include the \n",
    "development, research, and testing of the theories and programs \n",
    "to determine their effectiveness. The authors and publisher make \n",
    "no warranty of any kind, expressed or implied, with regard to these \n",
    "programs or to the documentation contained in these books. The authors \n",
    "and publisher shall not be liable in any event for incidental or \n",
    "consequential damages in connection with, or arising out of, the \n",
    "furnishing, performance, or use of these programs.                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.16 Ways to Store Tweets \n",
    "* **CSV files**\n",
    "* **pandas `DataFrame`s in memory**—CSV files easily loaded into **`DataFrame`s** for cleaning and manipulation\n",
    "* **SQL databases**\n",
    "* **NoSQL databases**—Twitter returns tweets as JSON documents, so **NoSQL JSON document databases like MongoDB** are natural (as you'll see later in the Big Data presentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "&copy;1992&ndash;2020 by Pearson Education, Inc. All Rights Reserved. This content is based on Chapter 5 of the book [**Intro to Python for Computer Science and Data Science: Learning to Program with AI, Big Data and the Cloud**](https://amzn.to/2VvdnxE).\n",
    "\n",
    "DISCLAIMER: The authors and publisher of this book have used their \n",
    "best efforts in preparing the book. These efforts include the \n",
    "development, research, and testing of the theories and programs \n",
    "to determine their effectiveness. The authors and publisher make \n",
    "no warranty of any kind, expressed or implied, with regard to these \n",
    "programs or to the documentation contained in these books. The authors \n",
    "and publisher shall not be liable in any event for incidental or \n",
    "consequential damages in connection with, or arising out of, the \n",
    "furnishing, performance, or use of these programs.                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.17 Twitter and Time Series\n",
    "* A **time series** is a sequence of values with timestamps. \n",
    "    * Daily closing stock prices, daily high temperatures at a given location, monthly U.S. job-creation numbers, quarterly earnings for a given company and more \n",
    "* **Tweets are natural for time-series analysis** because they’re **time stamped**\n",
    "* We'll demonstrate a time series when we discuss **machine learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "&copy;1992&ndash;2020 by Pearson Education, Inc. All Rights Reserved. This content is based on Chapter 5 of the book [**Intro to Python for Computer Science and Data Science: Learning to Program with AI, Big Data and the Cloud**](https://amzn.to/2VvdnxE).\n",
    "\n",
    "DISCLAIMER: The authors and publisher of this book have used their \n",
    "best efforts in preparing the book. These efforts include the \n",
    "development, research, and testing of the theories and programs \n",
    "to determine their effectiveness. The authors and publisher make \n",
    "no warranty of any kind, expressed or implied, with regard to these \n",
    "programs or to the documentation contained in these books. The authors \n",
    "and publisher shall not be liable in any event for incidental or \n",
    "consequential damages in connection with, or arising out of, the \n",
    "furnishing, performance, or use of these programs.                  "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
