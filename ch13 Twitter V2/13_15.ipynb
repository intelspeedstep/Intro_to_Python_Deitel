{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13.15 Geocoding and Mapping\n",
    "* Collect streaming tweets, then plot their locations on an interactive map\n",
    "* **Twitter disables precise location info (latitude/longitude) by default** (users must opt in to allowing Twitter to track locations) \n",
    "* Large percentage include the user’s home location information\n",
    "    * Sometimes invalid or fictitious \n",
    "* Map markers will show the sender's `location` and tweet text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### [**geopy** library](https://github.com/geopy/geopy)\n",
    "* Setup in Section 13.6\n",
    "* **Geocoding**&mdash;translate locations into **latitude** and **longitude**\n",
    "* **geopy** supports dozens of **geocoding web services**, many with **free or lite tiers**\n",
    "* We’ll use **OpenMapQuest geocoding service** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenMapQuest Geocoding API\n",
    "* Sign-up instructions in Section 13.6\n",
    "* Convert locations, such as **Boston, MA** into their **latitudes** and **longitudes**, such as **42.3602534** and **-71.0582912**, for plotting on maps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [**folium library**](https://github.com/python-visualization/folium) and Leaflet.js JavaScript Mapping Library\n",
    "* Setup in Section 13.6\n",
    "* For maps — uses **Leaflet.js JavaScript mapping library** to display maps in a web page \n",
    "* Folium save as HTML files that you can view in your web browser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 13.15.1 Getting and Mapping the Tweets\n",
    "* We’ll use utility functions from our **`tweetutilities.py`** file and class **`LocationListener`** in **`locationlistener.py`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collections Required By LocationListener\n",
    "* a list (`tweets`) to store the data from the tweets we collect \n",
    "* a dictionary (`counts`) to track the total number of tweets we collect and the number that have location data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [] \n",
    "\n",
    "counts = {'total_tweets': 0, 'locations': 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the LocationListener \n",
    "* Collect 50 tweets about `'football'`\n",
    "* `LocationListener` will use utility function `get_tweet_content` (located in `tweetutilities.py`; discussed in Section 13.15.2) to place in a dictionary the `username`, tweet `text` and user `location` from each tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keys\n",
    "\n",
    "import tweepy\n",
    "\n",
    "from locationlistener import LocationListener\n",
    "\n",
    "location_listener = LocationListener(\n",
    "    keys.bearer_token, counts_dict=counts, tweets_list=tweets,\n",
    "    topic='football', limit=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Redirect sys.stderr to sys.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.stderr = sys.stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete Existing StreamRules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = location_listener.get_rules().data\n",
    "\n",
    "rule_ids = [rule.id for rule in rules]\n",
    "\n",
    "location_listener.delete_rules(rule_ids)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a StreamRule\n",
    "* Rule to get tweets in English (`lang:en`) about football "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_listener.add_rules(\n",
    "    tweepy.StreamRule('football lang:en'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure and Start the Stream of Tweets\n",
    "* start streaming the tweets\n",
    "    * expansion `'author_id'` gets information about the user who sent the tweet, including the `username`\n",
    "    * `user_fields` argument specifies that the user information should include the account’s `'location'` \n",
    "    * `tweet_fields` argument specifies additional information to include with each tweet—in this case, the tweet’s `language`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_listener.filter(expansions=['author_id'], \n",
    "    user_fields=['location'], tweet_fields=['lang'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the Location Statistics\n",
    "* check how many tweets we processed, how many had locations and the percentage that had locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In [14]: counts['total_tweets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In [15]: counts['locations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In [16]: print(f'{counts[\"locations\"] / counts[\"total_tweets\"]:.1%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geocoding the Locations\n",
    "* Use `get_geocodes` utility function (from `tweetutilities.py`; discussed in Section 13.15.2) to geocode the location of each tweet stored in the list of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweetutilities import get_geocodes\n",
    "\n",
    "bad_locations = get_geocodes(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For each tweet with a valid location, the `get_geocodes` function adds the new keys `'latitude'` and `'longitude'` to that tweet’s dictionary in the `tweets` list — these will be used to plot map markers on our interactive map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the Bad Location Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{bad_locations / counts[\"locations\"]:.1%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the Data\n",
    "* Before we plot the tweet locations on a map, let’s use a pandas `DataFrame` to clean the data\n",
    "* When you create a * DataFrame* from the `tweets` list, it will contain the value `NaN` for the `'latitude'` and `'longitude'` of any tweet that does not have a valid location\n",
    "* `NaN` cannot be plotted on a map, so remove any rows containing `NaN` by calling the `DataFrame`’s `dropna` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Map with Folium\n",
    "Create a folium Map on which we’ll plot the tweet locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usmap = folium.Map(location=[39.8283, -98.5795], \n",
    "    tiles='Stamen Terrain', zoom_start=5, detect_retina=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `location` keyword argument specifies a sequence containing latitude and longitude coordinates for the **map’s center point** \n",
    "    * The values in this snippet are the **geographic center of the continental United States**\n",
    "    * In many places worldwide, the term `'football'` describes the sport we call soccer in the U.S., so some of the tweets we plot may be outside the U.S\n",
    "    * You can zoom using the **+** and **–** buttons at the map’s top-left, or you can dragging the map with the mouse (that is, pan) to see anywhere in the world\n",
    "*  `zoom_start` keyword argument specifies the map’s initial zoom level, lower values show more of the world\n",
    "* `detect_retina` keyword argument enables folium to detect high-resolution screens to use higher-resolution maps from `OpenStreetMap.org`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Popup Markers for the Tweet Locations\n",
    "* Create `folium` `Popup` objects containing each tweet’s text and add them to the `Map`\n",
    "* `DataFrame` method `itertuples` creates a named tuple from each row containing properties corresponding to each `DataFrame` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in df.itertuples():\n",
    "    text = ': '.join([t.username, t.text])\n",
    "    popup = folium.Popup(text, parse_html=True)\n",
    "    marker = folium.Marker((t.latitude, t.longitude), \n",
    "                           popup=popup)\n",
    "    marker.add_to(usmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Creates a string (`text`) containing the user’s `username` and tweet `text` \n",
    "* Creates a `folium` `Popup` to display the `text`\n",
    "* Creates a `folium` `Marker`\n",
    "    * tuple to specify the `Marker`’s latitude and longitude\n",
    "    * `popup` keyword argument associates the tweet’s `Popup` object with the new `Marker`\n",
    "* Calls the `Marker`’s `add_to` method to specify the `Map` that will display the `Marker`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Map\n",
    "* Call the `Map`’s `save` method to store the map in an HTML file, which you can then double-click to open in your web browser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "usmap.save('tweet_map.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usmap # displays the map in the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.15.2 Utility Functions in `tweetutilities.py` \n",
    "### `get_tweet_content` Utility Function \n",
    "* Receives a **`StreamResponse` object (`response`)** and creates a **dictionary** containing the **tweet’s `username`, `text` and `location`**\n",
    "\n",
    "```python\n",
    "def get_tweet_content(response):\n",
    "    \"\"\"Return dictionary with data from tweet.\"\"\"\n",
    "    fields = {}\n",
    "    fields['username'] = response.includes['users'][0].username\n",
    "    fields['text'] = response.data.text\n",
    "    fields['location'] = response.includes['users'][0].location\n",
    "\n",
    "    return fields\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `get_geocodes` Utility Function \n",
    "* Receives a list of dictionaries containing tweets and **geocodes their locations**\n",
    "* If geocoding is successful for a tweet, adds the **latitude** and **longitude** to the tweet’s **dictionary in `tweet_list`**\n",
    "* Requires class **`OpenMapQuest`** from the **geopy module**\n",
    "\n",
    "```python\n",
    "from geopy import OpenMapQuest\n",
    "```\n",
    "\n",
    "```python\n",
    "def get_geocodes(tweet_list):\n",
    "    \"\"\"Get the latitude and longitude for each tweet's location.\n",
    "    Returns the number of tweets with invalid location data.\"\"\"\n",
    "    print('Getting coordinates for tweet locations...')\n",
    "    geo = OpenMapQuest(api_key=keys.mapquest_key)  # geocoder\n",
    "    bad_locations = 0  \n",
    "\n",
    "    for tweet in tweet_list:\n",
    "        processed = False\n",
    "        delay = .1  # used if OpenMapQuest times out to delay next call\n",
    "        while not processed:\n",
    "            try:  # get coordinates for tweet['location']\n",
    "                geo_location = geo.geocode(tweet['location'])\n",
    "                processed = True\n",
    "            except:  # timed out, so wait before trying again\n",
    "                print('OpenMapQuest service timed out. Waiting.')\n",
    "                time.sleep(delay)\n",
    "                delay += .1\n",
    "\n",
    "        if geo_location:  \n",
    "            tweet['latitude'] = geo_location.latitude\n",
    "            tweet['longitude'] = geo_location.longitude\n",
    "        else:  \n",
    "            bad_locations += 1  # tweet['location'] was invalid\n",
    "    \n",
    "    print('Done geocoding')\n",
    "    return bad_locations\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `get_geocodes` Utility Function (cont.)\n",
    "* Creates the **`OpenMapQuest` object** we’ll use to geocode locations\n",
    "* Initializes **`bad_locations`** which we use to keep track of the number of invalid locations in the tweet objects we collected\n",
    "* Attempts to **geocode the current tweet’s location**\n",
    "* Prints a message that it’s done geocoding and returns the `bad_locations` value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.15.3 Class `LocationListener`\n",
    "```python\n",
    "# locationlistener.py\n",
    "\"\"\"Receives tweets matching a search string and stores a list of\n",
    "dictionaries containing each tweet's username/text/location.\"\"\"\n",
    "import tweepy\n",
    "from tweetutilities import get_tweet_content\n",
    "\n",
    "class LocationListener(tweepy.StreamingClient):\n",
    "    \"\"\"Handles incoming Tweet stream to get location data.\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    def __init__(self, bearer_token, counts_dict, \n",
    "                 tweets_list, topic, limit=10):\n",
    "        \"\"\"Configure the LocationListener.\"\"\"\n",
    "        self.tweets_list = tweets_list\n",
    "        self.counts_dict = counts_dict\n",
    "        self.topic = topic\n",
    "        self.TWEET_LIMIT = limit\n",
    "        super().__init__(bearer_token, wait_on_rate_limit=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    def on_response(self, response):\n",
    "        \"\"\"Called when Twitter pushes a new tweet to you.\"\"\"\n",
    "\n",
    "        # get each tweet's username, text and location\n",
    "        tweet_data = get_tweet_content(response)  \n",
    "\n",
    "        # ignore retweets and tweets that do not contain the topic\n",
    "        if (tweet_data['text'].startswith('RT') or\n",
    "            self.topic.lower() not in tweet_data['text'].lower()):\n",
    "            return\n",
    "\n",
    "        self.counts_dict['total_tweets'] += 1 # it's an original tweet\n",
    "\n",
    "        # ignore tweets with no location \n",
    "        if not tweet_data.get('location'):  \n",
    "            return\n",
    "\n",
    "        self.counts_dict['locations'] += 1 # user account has location\n",
    "        self.tweets_list.append(tweet_data) # store the tweet\n",
    "        print(f\"{tweet_data['username']}: {tweet_data['text']}\\n\")\n",
    "        \n",
    "        # if TWEET_LIMIT is reached, terminate streaming\n",
    "        if self.counts_dict['locations'] == self.TWEET_LIMIT:\n",
    "            self.disconnect()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.15.3 Class `LocationListener` (cont.)\n",
    "* `__init__` receives \n",
    "    * the `bearer_token` \n",
    "    * the number of tweets to process (`limit`)\n",
    "    * `counts` dictionary that we use to keep track of the total number of tweets processed\n",
    "    * `tweet_list` in which we store the dictionaries returned by the `get_tweet_content` utility function\n",
    "    * a string representing the topic so we can confirm that its text is contained in the tweet text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.15.3 Class `LocationListener` (cont.)\n",
    "* In method `on_response`\n",
    "   * Line 23 calls `get_tweet_content` to get each tweet’s screen name, text and location.\n",
    "    * Lines 26–28 ignore the tweet if it is a retweet or if the text does not include the topic we’re searching for\n",
    "    * Line 30 adds 1 to the value of the `'total_tweets'` key in the `counts` dictionary to track the number of original tweets\n",
    "    * Lines 33–34 ignore tweets that have no location data\n",
    "    * Line 36 adds 1 to the value of the `counts` dictionary’s `'locations'` key to indicate that we found a tweet with a location\n",
    "    * Line 37 appends the `tweet_data` dictionary to the `tweets_list`\n",
    "    * Line 38 displays the tweet’s screen name and tweet text so you can see that the app is making progress\n",
    "    * Lines 41–42 check whether the `TWEET_LIMIT` has been reached, and if so, disconnect from the stream."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "&copy;1992&ndash;2020 by Pearson Education, Inc. All Rights Reserved. This content is based on Chapter 5 of the book [**Intro to Python for Computer Science and Data Science: Learning to Program with AI, Big Data and the Cloud**](https://amzn.to/2VvdnxE).\n",
    "\n",
    "DISCLAIMER: The authors and publisher of this book have used their \n",
    "best efforts in preparing the book. These efforts include the \n",
    "development, research, and testing of the theories and programs \n",
    "to determine their effectiveness. The authors and publisher make \n",
    "no warranty of any kind, expressed or implied, with regard to these \n",
    "programs or to the documentation contained in these books. The authors \n",
    "and publisher shall not be liable in any event for incidental or \n",
    "consequential damages in connection with, or arising out of, the \n",
    "furnishing, performance, or use of these programs.                  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
